{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtHVti8i9NV4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Tuple, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score as accuracy, f1_score\n",
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib2 import Path\n",
        "from os.path import join\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Der8STJzGL-r"
      },
      "source": [
        "**Pre-Processing Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iTTWDMy5ILXX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "class WholeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, target):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(\"Accessing data at index\", idx, \"with shape:\", self.data[idx].shape)\n",
        "        return self.data[idx], self.target[idx]\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "def generate_batches(dataset, #ONLY GENERATES TWO BATCHES\n",
        "                     batch_size,\n",
        "                     shuffle=True,\n",
        "                     drop_last=False,\n",
        "                     device=\"cpu\",\n",
        "                     n_workers=0):\n",
        "    dataloader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            num_workers=n_workers,\n",
        "                            pin_memory=False)\n",
        "\n",
        "    for data, labels in dataloader:\n",
        "        #data = torch.unsqueeze(data, 1).float()\n",
        "        data = data.float()\n",
        "        labels = labels.float()\n",
        "        yield data.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "#Personally I think this should be applied to the data before it is split into\n",
        "#train, test, and val, but following CNNpred code, the test set losses seq_len\n",
        "#points with this method\n",
        "def create_windows(X, y, seq_len):\n",
        "  series = []\n",
        "  target = []\n",
        "  for i in range(len(X) - seq_len + 1):\n",
        "    series.append(X[i: i + seq_len])\n",
        "    target.append(y[i + seq_len - 1])\n",
        "\n",
        "  return np.array(series), np.array(target)\n",
        "\n",
        "\n",
        "def scale_X(X_train, X_val, X_test):\n",
        "  # Shapes of the arrays\n",
        "  num_samples_train, seq_length, num_stocks, num_features = X_train.shape\n",
        "  num_samples_val = X_val.shape[0]\n",
        "  num_samples_test = X_test.shape[0]\n",
        "\n",
        "  # Initialize a scaler for each feature\n",
        "  scalers = [StandardScaler() for _ in range(num_features)]\n",
        "\n",
        "  # Scale training data and prepare to scale validation and test data\n",
        "  X_train_scaled = np.empty_like(X_train)\n",
        "  X_val_scaled = np.empty_like(X_val)\n",
        "  X_test_scaled = np.empty_like(X_test)\n",
        "\n",
        "  # Scale each feature\n",
        "  for i in range(num_features):\n",
        "      # Extract the feature across all training data\n",
        "      feature_data_train = X_train[:, :, :, i].reshape(num_samples_train, seq_length * num_stocks)\n",
        "      \n",
        "      # Fit and transform training data\n",
        "      scalers[i].fit(feature_data_train)  # Fit only on training data\n",
        "      scaled_feature_data_train = scalers[i].transform(feature_data_train)\n",
        "      \n",
        "      # Transform validation data\n",
        "      feature_data_val = X_val[:, :, :, i].reshape(num_samples_val, seq_length * num_stocks)\n",
        "      scaled_feature_data_val = scalers[i].transform(feature_data_val)\n",
        "      \n",
        "      # Transform test data\n",
        "      feature_data_test = X_test[:, :, :, i].reshape(num_samples_test, seq_length * num_stocks)\n",
        "      scaled_feature_data_test = scalers[i].transform(feature_data_test)\n",
        "      \n",
        "      # Reshape scaled data back and store it in the correct position\n",
        "      X_train_scaled[:, :, :, i] = scaled_feature_data_train.reshape(num_samples_train, seq_length, num_stocks)\n",
        "      X_val_scaled[:, :, :, i] = scaled_feature_data_val.reshape(num_samples_val, seq_length, num_stocks)\n",
        "      X_test_scaled[:, :, :, i] = scaled_feature_data_test.reshape(num_samples_test, seq_length, num_stocks)\n",
        "\n",
        "  return X_train_scaled, X_val_scaled, X_test_scaled\n",
        "  # Now X_train_scaled, X_val_scaled, and X_test_scaled contain the appropriately scaled data\n",
        "\n",
        "\n",
        "def preprocess(data: dict,\n",
        "               seq_len: int,\n",
        "               Val_first: bool,\n",
        "               Trim_end: str,\n",
        "               Split_Date1: str,\n",
        "               Split_Date2: str,\n",
        "               n_day_predict: int = 1,) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "\n",
        "\n",
        "  X_all = []\n",
        "  y_all = {}\n",
        "\n",
        "  for index, df in data.items():\n",
        "\n",
        "    #Ensure it is sorted\n",
        "    df = df.sort_index()\n",
        "\n",
        "    #Get y\n",
        "    y_i = (df['close'][n_day_predict:] / df['close'][:-n_day_predict].values).astype(int)\n",
        "    y_i = y_i[:-n_day_predict]\n",
        "\n",
        "\n",
        "    #touch up data\n",
        "    X_i = df.fillna(0)\n",
        "    X_i = X_i[:-n_day_predict]\n",
        "    X_i = X_i[n_day_predict:]\n",
        "\n",
        "    X_all.append(X_i) \n",
        "    y_all[index] = y_i\n",
        "\n",
        "    #Get Trim index\n",
        "    Trim_index   = df.index.get_loc(Trim_end).start\n",
        "    Split_index1 = df.index.get_loc(Split_Date1).start\n",
        "    Split_index2 = df.index.get_loc(Split_Date2).start\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  y = {}\n",
        "    \n",
        "  for index, df in data.items():\n",
        "    X, y[index] = create_windows(np.transpose(np.array(X_all), (1, 0, 2)), np.array(y_all[index]).flatten(), seq_len)\n",
        "  \n",
        "  y_train = {}\n",
        "\n",
        "  y_test = {}\n",
        "\n",
        "  y_val = {}\n",
        "\n",
        "\n",
        "  #Split up into train, val, and training\n",
        "  if Val_first: #Puts the validation first\n",
        "     X_val = X[Trim_index:Split_index1]\n",
        "     X_train = X[Split_index1:Split_index2]\n",
        "     X_test = X[Split_index2:]\n",
        "     for index, _ in data.items():\n",
        "        y_val[index]   = y[index][Trim_index:Split_index1]\n",
        "        y_train[index] = y[index][Split_index1:Split_index2]\n",
        "        y_test[index]  = y[index][Split_index2:Split_index2+24] #THIS IS HARD CODED AS FUCK, the 24 is HARD CODED\n",
        "  else:\n",
        "    X_train = X[Trim_index:Split_index1]\n",
        "    X_val = X[Split_index1:Split_index2]\n",
        "    X_test = X[Split_index2:]\n",
        "    for index, _ in data.items():\n",
        "      y_train[index]   = y[index][Trim_index:Split_index1]\n",
        "      y_val[index] = y[index][Split_index1:Split_index2]\n",
        "      y_test[index]  = y[index][Split_index2:]\n",
        "  \n",
        "\n",
        "  #Scaling\n",
        "  X_train, X_val, X_test = scale_X(X_train, X_val, X_test)\n",
        "  \n",
        "\n",
        "  return X_train, y_train, X_test, y_test, X_val, y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiFDpaiT6Gj"
      },
      "source": [
        "**Utility Functions** Might combine with preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Urt_zmA6A1i1"
      },
      "outputs": [],
      "source": [
        "#Use for deriving next model filename\n",
        "def next_file(file, path):\n",
        "  #Ensure dicectory exists\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  #Get root and extension\n",
        "  filename, ext = os.path.splitext(file)\n",
        "\n",
        "  #Get list of files\n",
        "  files = os.listdir(path)\n",
        "  num = []\n",
        "  for file in files:\n",
        "    if file.startswith(filename):\n",
        "      num.append(int(re.findall(r'\\d+', file.split('-')[-1])[0]))\n",
        "\n",
        "  #Find next iteration number\n",
        "  file_iteration_number = max(num) + 1 if len(num) else 1\n",
        "  return join(path, filename + \"-\" + str(file_iteration_number) + ext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KoOV7hsvU22"
      },
      "source": [
        "**Engine Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzAp2PS4lsPF",
        "outputId": "e3f2deb9-8bca-412e-a0b1-ac6e77acfd13"
      },
      "outputs": [],
      "source": [
        "#Main.py script\n",
        "#Define Model and preprocessing params\n",
        "config_path = \"./Configs/crypto_hourly1day.yaml\" #TODO: Define config file, this will be done in command line\n",
        "with open(config_path, \"r\") as file:\n",
        "  config = yaml.safe_load(file)\n",
        "\n",
        "with open(config['preprocess']['dataset_path'], 'rb') as file:\n",
        "  data = pickle.load(file)\n",
        "\n",
        "\n",
        "preparams = {\n",
        "    \"data\": data,\n",
        "    \"seq_len\": config['preprocess']['seq_len'],\n",
        "    \"Val_first\": str(config['preprocess']['Val_first']),\n",
        "    \"Trim_end\": str(config['preprocess']['Trim_end']),\n",
        "    \"Split_Date1\": str(config['preprocess']['Split_Date1']),\n",
        "    \"Split_Date2\": str(config['preprocess']['Split_Date2']),\n",
        "    \"n_day_predict\": config['preprocess']['n_day_predict'],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DotCxsDOe38",
        "outputId": "154a76fb-1fb7-4ce2-f927-32849dff679c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(252, 82, 60, 5)\n",
            "(252, 82, 60, 5)\n",
            "(252, 82, 60, 5)\n",
            "(252, 82, 60, 5)\n",
            "(252, 82, 60, 5)\n"
          ]
        }
      ],
      "source": [
        "#Main.py script\n",
        "#preprocess data\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = preprocess(**preparams)\n",
        "\n",
        "#Dict of Datasets\n",
        "train_data = {}\n",
        "val_data = {}\n",
        "test_data = {}\n",
        "\n",
        "#Dict of batch generaters\n",
        "train_dataloader = {}\n",
        "\n",
        "#Create wholedatasets in dict for each stock\n",
        "#Create batch generator for training\n",
        "\n",
        "\n",
        "X_val = X_val.transpose(0, 3, 1, 2) #TEMP\n",
        "X_test = X_test.transpose(0, 3, 1, 2) #TEMP\n",
        "\n",
        "X_train = X_train.transpose(0, 3, 1, 2) #TEMP\n",
        "for index, y_train_i in y_train.items():\n",
        "  train_data[index] = WholeDataset(X_train, y_train_i)\n",
        "  # train_dataloader[index] = generate_batches(train_data[index], config['train']['batch_size'], config['train']['num_workers']) #TODO: Replace 128 and 0 with .yaml settings\n",
        "  #Train_dataloader moved to training loop, as it needs to be re init every time\n",
        "\n",
        "for index, y_val_i in y_val.items():\n",
        "\n",
        "  val_data[index] = WholeDataset(X_val, y_val_i)\n",
        "\n",
        "for index, y_test_i in y_test.items():\n",
        "  test_data[index] = WholeDataset(X_test, y_test_i)\n",
        "  print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kdFnleVyd1AD"
      },
      "outputs": [],
      "source": [
        "class CNNModelOne(nn.Module):\n",
        "    def __init__(self, number_filter, number_of_stocks, seq_len, number_feature, drop, calculated_fc_layer_size):\n",
        "        super(CNNModelOne, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        #self.conv1 = nn.Conv2d(in_channels=number_feature, out_channels=number_filter[0], kernel_size=(1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels=82, out_channels=8, kernel_size=(1, 1))\n",
        "        # Layer 2\n",
        "        #self.conv2 = nn.Conv2d(in_channels=number_filter[0], out_channels=number_filter[1], kernel_size=(1, 3))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 5))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Flatten and Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(calculated_fc_layer_size, 1)  # Calculate based on output size after last pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        torch.Size([128, 82, 60, 5])\n",
        "        torch.Size([128, 8, 60, 5])\n",
        "        torch.Size([128, 8, 58, 1])\n",
        "        torch.Size([128, 8, 29, 1])\n",
        "        torch.Size([128, 8, 27, 1])\n",
        "        torch.Size([128, 8, 13, 1])\n",
        "        torch.Size([128, 104])\n",
        "        torch.Size([128, 104])\n",
        "        \"\"\"\n",
        "        #print(\"-----------------x-x-xxx--------------\")\n",
        "        #print(x.shape) # torch.Size([128, 82, 60, 5])\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 60, 5])\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 58, 1])\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 29, 1])\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 27, 1])\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 13, 1])\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = self.dropout(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KnpvMeGq4bMm"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Train.py script\n",
        "def validate(config, model, dataset):\n",
        "    model.eval()\n",
        "    loss_fcn = torch.nn.BCELoss().to(device)\n",
        "\n",
        "    data_dataloader = generate_batches(dataset, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_label in data_dataloader:\n",
        "\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_label = batch_label.to(device)\n",
        "\n",
        "            \n",
        "            batch_logit = model(batch_data).view(-1)\n",
        "\n",
        "            loss = loss_fcn(batch_logit, batch_label)\n",
        "\n",
        "            pred = (batch_logit > 0.5).int()\n",
        "\n",
        "            pred_list.extend(pred.cpu().numpy())\n",
        "            label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "        loss_data = np.array(loss_list).mean()\n",
        "        acc = accuracy(pred_list, label_list)\n",
        "        f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    return loss_data, acc, f1,\n",
        "def train(config, train_data, val_dataset, test_dataset): #Test_dataset SHOULD NOT BE A PARAMETER!!!!!\n",
        "  #Init Model\n",
        "  #model_class = getattr(models, config['model']['type'])\n",
        "  #model = model_class(**config['model']['params'])\n",
        "\n",
        "  ####DEBUG DEBUG DEBUG\n",
        "  model = CNNModelOne(number_filter=[8,8,8], number_of_stocks=5, seq_len=60, number_feature=82, drop=0.1, calculated_fc_layer_size =104)\n",
        "  model = model.to(device)\n",
        "  # print(\"-------Model----------\")\n",
        "  # print(model)\n",
        "  # print(model.conv3.kernel_size)\n",
        "  # print(model.conv3.padding)\n",
        "  # print(\"-------Model----------\")\n",
        "\n",
        "  #Init loss function\n",
        "  #loss_fcn = torch.nn.BCELoss()\n",
        "  #loss_class = getattr(nn, config['loss_function']['type'])\n",
        "  #loss_fcn = loss_class(**config['loss_function']['params']).to(device)\n",
        "  loss_fcn = nn.BCELoss().to(device)\n",
        "\n",
        "\n",
        "  #Init Optimizer\n",
        "  #optimizer_class = getattr(optim, config['optimizer']['type'])\n",
        "  #optimizer = optimizer_class(model.parameters(), **{k: v for k, v in config['optimizer'].items() if k != 'type'})\n",
        "\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Init Scheduler\n",
        "  #scheduler_class = getattr(optim.lr_scheduler, config['scheduler']['type'])\n",
        "  #scheduler = scheduler_class(optimizer, **{k: v for k, v in config['scheduler'].items() if k != 'type'})\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  #scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True, eps=1e-8)\n",
        "  for epoch in range(config['train']['epoch']):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    #train_dataloader\n",
        "    train_dataloader = generate_batches(train_data, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    for batch_data, batch_label in train_dataloader:\n",
        "      # print(\"-------bd----------\")\n",
        "      # print(batch_data.shape)\n",
        "      # print(\"-------------------\")\n",
        "      batch_data = batch_data.to(device) #\n",
        "      batch_label = batch_label.to(device) #\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      batch_logit = model(batch_data).view(-1)\n",
        "      loss = loss_fcn(batch_logit, batch_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # print(\"Batch_logit\")\n",
        "      # print(batch_logit)\n",
        "\n",
        "      #Convert to CPU for processing\n",
        "      batch_data = batch_data.cpu()\n",
        "      batch_label = batch_label.cpu()\n",
        "\n",
        "\n",
        "      pred = (batch_logit > 0.5).int()\n",
        "      # print(\"Pred\")\n",
        "      # print(pred)\n",
        "\n",
        "      pred_list.extend(pred.cpu().numpy())\n",
        "      label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "      \n",
        "      parameters = list(model.parameters())\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "    loss_data = np.array(loss_list).mean()\n",
        "\n",
        "    train_acc = accuracy(pred_list, label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "    # print(train_acc)\n",
        "    # print(pred_list)\n",
        "    # print(label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "\n",
        "    train_f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    print(\"Epoch {:05d}\\n\"\n",
        "          \"Train: loss: {:.4f} | accuracy: {:.4f} | f-acore: {:.4f}\"\n",
        "          .format(epoch + 1, loss_data, train_acc, train_f1))\n",
        "    #loss_data = float(loss_data.item())\n",
        "\n",
        "    #loss_data = torch.tensor(loss_data)\n",
        "    \n",
        "    #scheduler.step(loss_data) SCHEDULER REMOVE FOR NOW\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    test_loss, test_acc, test_f1 = validate(config, model, test_dataset)\n",
        "    print(\"Test:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(test_loss, test_acc, test_f1))\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    \n",
        "    val_loss, val_acc, val_f1 = validate(config, model, val_dataset)\n",
        "    print(\"Validation:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(val_loss, val_acc, val_f1))\n",
        "    #   # choosing best model according to best validation accuracy\n",
        "    #   if best_f1 < val_f1:\n",
        "    #       best_f1 = val_f1\n",
        "    #       cur_step = 0\n",
        "    #       torch.save(model, filepath)\n",
        "\n",
        "      # else:\n",
        "      #     cur_step += 1\n",
        "      #     if cur_step == config['train']['patience']:\n",
        "      #         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_m91VyEo3Ib",
        "outputId": "5a116a3a-4e07-46fe-a128-76b8c217b718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 3070\n",
            "-----------------------------------------------------------------------------------------\n",
            "BTC-USD\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6917 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6900 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6916 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00002\n",
            "Train: loss: 0.6911 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6897 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00003\n",
            "Train: loss: 0.6896 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6893 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6922 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00004\n",
            "Train: loss: 0.6893 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6886 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00005\n",
            "Train: loss: 0.6898 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6878 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6912 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00006\n",
            "Train: loss: 0.6894 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6876 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00007\n",
            "Train: loss: 0.6890 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6874 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00008\n",
            "Train: loss: 0.6924 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6871 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6932 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00009\n",
            "Train: loss: 0.6868 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6875 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6921 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00010\n",
            "Train: loss: 0.6908 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6871 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00011\n",
            "Train: loss: 0.6882 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6869 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6918 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00012\n",
            "Train: loss: 0.6854 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6870 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00013\n",
            "Train: loss: 0.6861 | accuracy: 0.5345 | f-acore: 0.3483\n",
            "Test:  loss: 0.6862 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6917 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00014\n",
            "Train: loss: 0.6834 | accuracy: 0.5359 | f-acore: 0.3517\n",
            "Test:  loss: 0.6852 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6928 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00015\n",
            "Train: loss: 0.6873 | accuracy: 0.5374 | f-acore: 0.3551\n",
            "Test:  loss: 0.6846 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00016\n",
            "Train: loss: 0.6851 | accuracy: 0.5460 | f-acore: 0.3776\n",
            "Test:  loss: 0.6853 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6936 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00017\n",
            "Train: loss: 0.6852 | accuracy: 0.5417 | f-acore: 0.4098\n",
            "Test:  loss: 0.6847 | accuracy: 0.5833 | f1: 0.4444\n",
            "Validation:  loss: 0.6950 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00018\n",
            "Train: loss: 0.6824 | accuracy: 0.5618 | f-acore: 0.4705\n",
            "Test:  loss: 0.6837 | accuracy: 0.6667 | f1: 0.5966\n",
            "Validation:  loss: 0.6938 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00019\n",
            "Train: loss: 0.6823 | accuracy: 0.5503 | f-acore: 0.4307\n",
            "Test:  loss: 0.6811 | accuracy: 0.5417 | f1: 0.3514\n",
            "Validation:  loss: 0.6947 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00020\n",
            "Train: loss: 0.6798 | accuracy: 0.5489 | f-acore: 0.4221\n",
            "Test:  loss: 0.6812 | accuracy: 0.7083 | f1: 0.6606\n",
            "Validation:  loss: 0.6921 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00021\n",
            "Train: loss: 0.6802 | accuracy: 0.5704 | f-acore: 0.4794\n",
            "Test:  loss: 0.6795 | accuracy: 0.7500 | f1: 0.7188\n",
            "Validation:  loss: 0.6948 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00022\n",
            "Train: loss: 0.6802 | accuracy: 0.5647 | f-acore: 0.5008\n",
            "Test:  loss: 0.6812 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6949 | accuracy: 0.5298 | f1: 0.3463\n",
            "Epoch 00023\n",
            "Train: loss: 0.6795 | accuracy: 0.5704 | f-acore: 0.5407\n",
            "Test:  loss: 0.6792 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5238 | f1: 0.3796\n",
            "Epoch 00024\n",
            "Train: loss: 0.6802 | accuracy: 0.5575 | f-acore: 0.5301\n",
            "Test:  loss: 0.6775 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6937 | accuracy: 0.5298 | f1: 0.4005\n",
            "Epoch 00025\n",
            "Train: loss: 0.6767 | accuracy: 0.5790 | f-acore: 0.5540\n",
            "Test:  loss: 0.6749 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6941 | accuracy: 0.5238 | f1: 0.4053\n",
            "Epoch 00026\n",
            "Train: loss: 0.6728 | accuracy: 0.5862 | f-acore: 0.5612\n",
            "Test:  loss: 0.6725 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6967 | accuracy: 0.5208 | f1: 0.4035\n",
            "Epoch 00027\n",
            "Train: loss: 0.6739 | accuracy: 0.5704 | f-acore: 0.5474\n",
            "Test:  loss: 0.6726 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6963 | accuracy: 0.5179 | f1: 0.4330\n",
            "Epoch 00028\n",
            "Train: loss: 0.6720 | accuracy: 0.5876 | f-acore: 0.5730\n",
            "Test:  loss: 0.6711 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6975 | accuracy: 0.5119 | f1: 0.4320\n",
            "Epoch 00029\n",
            "Train: loss: 0.6767 | accuracy: 0.5690 | f-acore: 0.5350\n",
            "Test:  loss: 0.6675 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6996 | accuracy: 0.5208 | f1: 0.4112\n",
            "Epoch 00030\n",
            "Train: loss: 0.6735 | accuracy: 0.5891 | f-acore: 0.5752\n",
            "Test:  loss: 0.6737 | accuracy: 0.5000 | f1: 0.4965\n",
            "Validation:  loss: 0.6964 | accuracy: 0.5119 | f1: 0.4884\n",
            "Epoch 00031\n",
            "Train: loss: 0.6762 | accuracy: 0.5632 | f-acore: 0.5577\n",
            "Test:  loss: 0.6697 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5089 | f1: 0.4601\n",
            "Epoch 00032\n",
            "Train: loss: 0.6729 | accuracy: 0.5848 | f-acore: 0.5751\n",
            "Test:  loss: 0.6658 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7003 | accuracy: 0.5149 | f1: 0.4601\n",
            "Epoch 00033\n",
            "Train: loss: 0.6706 | accuracy: 0.6063 | f-acore: 0.5902\n",
            "Test:  loss: 0.6636 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6961 | accuracy: 0.5208 | f1: 0.4829\n",
            "Epoch 00034\n",
            "Train: loss: 0.6715 | accuracy: 0.5876 | f-acore: 0.5689\n",
            "Test:  loss: 0.6633 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6949 | accuracy: 0.5119 | f1: 0.4841\n",
            "Epoch 00035\n",
            "Train: loss: 0.6682 | accuracy: 0.5833 | f-acore: 0.5683\n",
            "Test:  loss: 0.6656 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6993 | accuracy: 0.5149 | f1: 0.4960\n",
            "Epoch 00036\n",
            "Train: loss: 0.6689 | accuracy: 0.5833 | f-acore: 0.5753\n",
            "Test:  loss: 0.6635 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6967 | accuracy: 0.5119 | f1: 0.4884\n",
            "Epoch 00037\n",
            "Train: loss: 0.6660 | accuracy: 0.6020 | f-acore: 0.5908\n",
            "Test:  loss: 0.6609 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7014 | accuracy: 0.5119 | f1: 0.4705\n",
            "Epoch 00038\n",
            "Train: loss: 0.6682 | accuracy: 0.5948 | f-acore: 0.5704\n",
            "Test:  loss: 0.6586 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6997 | accuracy: 0.5208 | f1: 0.4773\n",
            "Epoch 00039\n",
            "Train: loss: 0.6699 | accuracy: 0.5905 | f-acore: 0.5691\n",
            "Test:  loss: 0.6589 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5149 | f1: 0.4865\n",
            "Epoch 00040\n",
            "Train: loss: 0.6601 | accuracy: 0.6092 | f-acore: 0.6022\n",
            "Test:  loss: 0.6601 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.6984 | accuracy: 0.5238 | f1: 0.5081\n",
            "Epoch 00041\n",
            "Train: loss: 0.6670 | accuracy: 0.6121 | f-acore: 0.6074\n",
            "Test:  loss: 0.6565 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7007 | accuracy: 0.5149 | f1: 0.4935\n",
            "Epoch 00042\n",
            "Train: loss: 0.6701 | accuracy: 0.5891 | f-acore: 0.5733\n",
            "Test:  loss: 0.6532 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7023 | accuracy: 0.5149 | f1: 0.4880\n",
            "Epoch 00043\n",
            "Train: loss: 0.6651 | accuracy: 0.5948 | f-acore: 0.5722\n",
            "Test:  loss: 0.6529 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7010 | accuracy: 0.5060 | f1: 0.4713\n",
            "Epoch 00044\n",
            "Train: loss: 0.6600 | accuracy: 0.5862 | f-acore: 0.5752\n",
            "Test:  loss: 0.6550 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.6995 | accuracy: 0.5119 | f1: 0.4884\n",
            "Epoch 00045\n",
            "Train: loss: 0.6611 | accuracy: 0.5934 | f-acore: 0.5878\n",
            "Test:  loss: 0.6515 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7048 | accuracy: 0.5119 | f1: 0.4870\n",
            "Epoch 00046\n",
            "Train: loss: 0.6608 | accuracy: 0.5948 | f-acore: 0.5767\n",
            "Test:  loss: 0.6490 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7033 | accuracy: 0.5179 | f1: 0.4710\n",
            "Epoch 00047\n",
            "Train: loss: 0.6637 | accuracy: 0.5920 | f-acore: 0.5673\n",
            "Test:  loss: 0.6488 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7037 | accuracy: 0.5179 | f1: 0.4873\n",
            "Epoch 00048\n",
            "Train: loss: 0.6633 | accuracy: 0.6006 | f-acore: 0.5967\n",
            "Test:  loss: 0.6539 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.7050 | accuracy: 0.5327 | f1: 0.5226\n",
            "Epoch 00049\n",
            "Train: loss: 0.6603 | accuracy: 0.6164 | f-acore: 0.6148\n",
            "Test:  loss: 0.6454 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7065 | accuracy: 0.5238 | f1: 0.5035\n",
            "Epoch 00050\n",
            "Train: loss: 0.6568 | accuracy: 0.6078 | f-acore: 0.5942\n",
            "Test:  loss: 0.6415 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7010 | accuracy: 0.5060 | f1: 0.4600\n",
            "Epoch 00051\n",
            "Train: loss: 0.6636 | accuracy: 0.5891 | f-acore: 0.5769\n",
            "Test:  loss: 0.6421 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7053 | accuracy: 0.5268 | f1: 0.5060\n",
            "Epoch 00052\n",
            "Train: loss: 0.6624 | accuracy: 0.5862 | f-acore: 0.5829\n",
            "Test:  loss: 0.6431 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7051 | accuracy: 0.5298 | f1: 0.5109\n",
            "Epoch 00053\n",
            "Train: loss: 0.6570 | accuracy: 0.5991 | f-acore: 0.5925\n",
            "Test:  loss: 0.6406 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7035 | accuracy: 0.5268 | f1: 0.5033\n",
            "Epoch 00054\n",
            "Train: loss: 0.6505 | accuracy: 0.6063 | f-acore: 0.5921\n",
            "Test:  loss: 0.6390 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7035 | accuracy: 0.5238 | f1: 0.4981\n",
            "Epoch 00055\n",
            "Train: loss: 0.6526 | accuracy: 0.6135 | f-acore: 0.6006\n",
            "Test:  loss: 0.6389 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7094 | accuracy: 0.5268 | f1: 0.5033\n",
            "Epoch 00056\n",
            "Train: loss: 0.6505 | accuracy: 0.6178 | f-acore: 0.6022\n",
            "Test:  loss: 0.6371 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7091 | accuracy: 0.5030 | f1: 0.4636\n",
            "Epoch 00057\n",
            "Train: loss: 0.6497 | accuracy: 0.6106 | f-acore: 0.5959\n",
            "Test:  loss: 0.6361 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7059 | accuracy: 0.5208 | f1: 0.4897\n",
            "Epoch 00058\n",
            "Train: loss: 0.6468 | accuracy: 0.6293 | f-acore: 0.6180\n",
            "Test:  loss: 0.6345 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7064 | accuracy: 0.5298 | f1: 0.5071\n",
            "Epoch 00059\n",
            "Train: loss: 0.6479 | accuracy: 0.6193 | f-acore: 0.6093\n",
            "Test:  loss: 0.6341 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7083 | accuracy: 0.5298 | f1: 0.5071\n",
            "Epoch 00060\n",
            "Train: loss: 0.6539 | accuracy: 0.6020 | f-acore: 0.5951\n",
            "Test:  loss: 0.6363 | accuracy: 0.5833 | f1: 0.5714\n",
            "Validation:  loss: 0.7124 | accuracy: 0.5298 | f1: 0.5132\n",
            "Epoch 00061\n",
            "Train: loss: 0.6529 | accuracy: 0.6193 | f-acore: 0.6169\n",
            "Test:  loss: 0.6339 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7129 | accuracy: 0.5268 | f1: 0.5047\n",
            "Epoch 00062\n",
            "Train: loss: 0.6469 | accuracy: 0.6365 | f-acore: 0.6277\n",
            "Test:  loss: 0.6288 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7106 | accuracy: 0.5149 | f1: 0.4727\n",
            "Epoch 00063\n",
            "Train: loss: 0.6468 | accuracy: 0.6394 | f-acore: 0.6239\n",
            "Test:  loss: 0.6264 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7136 | accuracy: 0.5208 | f1: 0.4881\n",
            "Epoch 00064\n",
            "Train: loss: 0.6478 | accuracy: 0.6236 | f-acore: 0.6150\n",
            "Test:  loss: 0.6279 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7108 | accuracy: 0.5268 | f1: 0.5128\n",
            "Epoch 00065\n",
            "Train: loss: 0.6457 | accuracy: 0.6164 | f-acore: 0.6116\n",
            "Test:  loss: 0.6217 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7095 | accuracy: 0.5327 | f1: 0.5109\n",
            "Epoch 00066\n",
            "Train: loss: 0.6462 | accuracy: 0.6164 | f-acore: 0.6071\n",
            "Test:  loss: 0.6205 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7083 | accuracy: 0.5298 | f1: 0.5084\n",
            "Epoch 00067\n",
            "Train: loss: 0.6452 | accuracy: 0.6451 | f-acore: 0.6362\n",
            "Test:  loss: 0.6218 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7113 | accuracy: 0.5268 | f1: 0.5072\n",
            "Epoch 00068\n",
            "Train: loss: 0.6418 | accuracy: 0.6480 | f-acore: 0.6401\n",
            "Test:  loss: 0.6208 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7141 | accuracy: 0.5268 | f1: 0.5072\n",
            "Epoch 00069\n",
            "Train: loss: 0.6539 | accuracy: 0.6236 | f-acore: 0.6174\n",
            "Test:  loss: 0.6213 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7113 | accuracy: 0.5238 | f1: 0.5022\n",
            "Epoch 00070\n",
            "Train: loss: 0.6383 | accuracy: 0.6264 | f-acore: 0.6165\n",
            "Test:  loss: 0.6202 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7079 | accuracy: 0.5208 | f1: 0.4943\n",
            "Epoch 00071\n",
            "Train: loss: 0.6423 | accuracy: 0.6264 | f-acore: 0.6172\n",
            "Test:  loss: 0.6196 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7066 | accuracy: 0.5208 | f1: 0.4913\n",
            "Epoch 00072\n",
            "Train: loss: 0.6385 | accuracy: 0.6394 | f-acore: 0.6285\n",
            "Test:  loss: 0.6181 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7130 | accuracy: 0.5179 | f1: 0.4904\n",
            "Epoch 00073\n",
            "Train: loss: 0.6359 | accuracy: 0.6480 | f-acore: 0.6388\n",
            "Test:  loss: 0.6149 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7102 | accuracy: 0.5208 | f1: 0.4997\n",
            "Epoch 00074\n",
            "Train: loss: 0.6354 | accuracy: 0.6480 | f-acore: 0.6407\n",
            "Test:  loss: 0.6104 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7120 | accuracy: 0.5208 | f1: 0.5022\n",
            "Epoch 00075\n",
            "Train: loss: 0.6405 | accuracy: 0.6149 | f-acore: 0.6078\n",
            "Test:  loss: 0.6093 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7135 | accuracy: 0.5238 | f1: 0.5081\n",
            "Epoch 00076\n",
            "Train: loss: 0.6345 | accuracy: 0.6379 | f-acore: 0.6323\n",
            "Test:  loss: 0.6118 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7138 | accuracy: 0.5208 | f1: 0.5045\n",
            "Epoch 00077\n",
            "Train: loss: 0.6380 | accuracy: 0.6365 | f-acore: 0.6315\n",
            "Test:  loss: 0.6138 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7177 | accuracy: 0.5179 | f1: 0.4947\n",
            "Epoch 00078\n",
            "Train: loss: 0.6373 | accuracy: 0.6336 | f-acore: 0.6270\n",
            "Test:  loss: 0.6124 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5179 | f1: 0.4873\n",
            "Epoch 00079\n",
            "Train: loss: 0.6266 | accuracy: 0.6422 | f-acore: 0.6339\n",
            "Test:  loss: 0.6123 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7104 | accuracy: 0.5208 | f1: 0.4957\n",
            "Epoch 00080\n",
            "Train: loss: 0.6294 | accuracy: 0.6422 | f-acore: 0.6326\n",
            "Test:  loss: 0.6093 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7122 | accuracy: 0.5179 | f1: 0.5020\n",
            "Epoch 00081\n",
            "Train: loss: 0.6273 | accuracy: 0.6394 | f-acore: 0.6336\n",
            "Test:  loss: 0.6086 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7113 | accuracy: 0.5119 | f1: 0.4990\n",
            "Epoch 00082\n",
            "Train: loss: 0.6222 | accuracy: 0.6566 | f-acore: 0.6521\n",
            "Test:  loss: 0.6089 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7141 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00083\n",
            "Train: loss: 0.6252 | accuracy: 0.6293 | f-acore: 0.6238\n",
            "Test:  loss: 0.6126 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7170 | accuracy: 0.5149 | f1: 0.4849\n",
            "Epoch 00084\n",
            "Train: loss: 0.6296 | accuracy: 0.6437 | f-acore: 0.6287\n",
            "Test:  loss: 0.6147 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7183 | accuracy: 0.5298 | f1: 0.4934\n",
            "Epoch 00085\n",
            "Train: loss: 0.6349 | accuracy: 0.6480 | f-acore: 0.6413\n",
            "Test:  loss: 0.6105 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7115 | accuracy: 0.5179 | f1: 0.5041\n",
            "Epoch 00086\n",
            "Train: loss: 0.6312 | accuracy: 0.6293 | f-acore: 0.6271\n",
            "Test:  loss: 0.6060 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7111 | accuracy: 0.5000 | f1: 0.4887\n",
            "Epoch 00087\n",
            "Train: loss: 0.6219 | accuracy: 0.6537 | f-acore: 0.6466\n",
            "Test:  loss: 0.6010 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7159 | accuracy: 0.5357 | f1: 0.5032\n",
            "Epoch 00088\n",
            "Train: loss: 0.6163 | accuracy: 0.6609 | f-acore: 0.6532\n",
            "Test:  loss: 0.6040 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7162 | accuracy: 0.5208 | f1: 0.4984\n",
            "Epoch 00089\n",
            "Train: loss: 0.6220 | accuracy: 0.6509 | f-acore: 0.6448\n",
            "Test:  loss: 0.5994 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7111 | accuracy: 0.5089 | f1: 0.4944\n",
            "Epoch 00090\n",
            "Train: loss: 0.6078 | accuracy: 0.6595 | f-acore: 0.6557\n",
            "Test:  loss: 0.6008 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7163 | accuracy: 0.4911 | f1: 0.4800\n",
            "Epoch 00091\n",
            "Train: loss: 0.6106 | accuracy: 0.6667 | f-acore: 0.6617\n",
            "Test:  loss: 0.5992 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7124 | accuracy: 0.5268 | f1: 0.4991\n",
            "Epoch 00092\n",
            "Train: loss: 0.6050 | accuracy: 0.6767 | f-acore: 0.6695\n",
            "Test:  loss: 0.6021 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7161 | accuracy: 0.5238 | f1: 0.4921\n",
            "Epoch 00093\n",
            "Train: loss: 0.6240 | accuracy: 0.6466 | f-acore: 0.6397\n",
            "Test:  loss: 0.5979 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7197 | accuracy: 0.5268 | f1: 0.4960\n",
            "Epoch 00094\n",
            "Train: loss: 0.6067 | accuracy: 0.6537 | f-acore: 0.6482\n",
            "Test:  loss: 0.5931 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7175 | accuracy: 0.5238 | f1: 0.4921\n",
            "Epoch 00095\n",
            "Train: loss: 0.6042 | accuracy: 0.6652 | f-acore: 0.6568\n",
            "Test:  loss: 0.5951 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7256 | accuracy: 0.5387 | f1: 0.4967\n",
            "Epoch 00096\n",
            "Train: loss: 0.6197 | accuracy: 0.6624 | f-acore: 0.6545\n",
            "Test:  loss: 0.5950 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7222 | accuracy: 0.5327 | f1: 0.5008\n",
            "Epoch 00097\n",
            "Train: loss: 0.6085 | accuracy: 0.6667 | f-acore: 0.6631\n",
            "Test:  loss: 0.5947 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7142 | accuracy: 0.4970 | f1: 0.4821\n",
            "Epoch 00098\n",
            "Train: loss: 0.6071 | accuracy: 0.6609 | f-acore: 0.6561\n",
            "Test:  loss: 0.5931 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7241 | accuracy: 0.5327 | f1: 0.4940\n",
            "Epoch 00099\n",
            "Train: loss: 0.6069 | accuracy: 0.6494 | f-acore: 0.6355\n",
            "Test:  loss: 0.5952 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7261 | accuracy: 0.5357 | f1: 0.4981\n",
            "Epoch 00100\n",
            "Train: loss: 0.6039 | accuracy: 0.6695 | f-acore: 0.6651\n",
            "Test:  loss: 0.5973 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7166 | accuracy: 0.4821 | f1: 0.4754\n",
            "Epoch 00101\n",
            "Train: loss: 0.6088 | accuracy: 0.6739 | f-acore: 0.6715\n",
            "Test:  loss: 0.5968 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7168 | accuracy: 0.4970 | f1: 0.4787\n",
            "Epoch 00102\n",
            "Train: loss: 0.6020 | accuracy: 0.6825 | f-acore: 0.6781\n",
            "Test:  loss: 0.5939 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7242 | accuracy: 0.5268 | f1: 0.4944\n",
            "Epoch 00103\n",
            "Train: loss: 0.5878 | accuracy: 0.6839 | f-acore: 0.6767\n",
            "Test:  loss: 0.5884 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7220 | accuracy: 0.5149 | f1: 0.4880\n",
            "Epoch 00104\n",
            "Train: loss: 0.6007 | accuracy: 0.6825 | f-acore: 0.6777\n",
            "Test:  loss: 0.5909 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7312 | accuracy: 0.5298 | f1: 0.4951\n",
            "Epoch 00105\n",
            "Train: loss: 0.5916 | accuracy: 0.6782 | f-acore: 0.6708\n",
            "Test:  loss: 0.5860 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7270 | accuracy: 0.5030 | f1: 0.4784\n",
            "Epoch 00106\n",
            "Train: loss: 0.5961 | accuracy: 0.6695 | f-acore: 0.6669\n",
            "Test:  loss: 0.5835 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7271 | accuracy: 0.4792 | f1: 0.4705\n",
            "Epoch 00107\n",
            "Train: loss: 0.5852 | accuracy: 0.6796 | f-acore: 0.6773\n",
            "Test:  loss: 0.5902 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7297 | accuracy: 0.5089 | f1: 0.4832\n",
            "Epoch 00108\n",
            "Train: loss: 0.5970 | accuracy: 0.6839 | f-acore: 0.6746\n",
            "Test:  loss: 0.5954 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7301 | accuracy: 0.5357 | f1: 0.4981\n",
            "Epoch 00109\n",
            "Train: loss: 0.5921 | accuracy: 0.6940 | f-acore: 0.6879\n",
            "Test:  loss: 0.5873 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7281 | accuracy: 0.5030 | f1: 0.4811\n",
            "Epoch 00110\n",
            "Train: loss: 0.5947 | accuracy: 0.6710 | f-acore: 0.6683\n",
            "Test:  loss: 0.5909 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7297 | accuracy: 0.5119 | f1: 0.4884\n",
            "Epoch 00111\n",
            "Train: loss: 0.5910 | accuracy: 0.6954 | f-acore: 0.6892\n",
            "Test:  loss: 0.5949 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7256 | accuracy: 0.5208 | f1: 0.4957\n",
            "Epoch 00112\n",
            "Train: loss: 0.5984 | accuracy: 0.6825 | f-acore: 0.6789\n",
            "Test:  loss: 0.5909 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7267 | accuracy: 0.4940 | f1: 0.4774\n",
            "Epoch 00113\n",
            "Train: loss: 0.5838 | accuracy: 0.6940 | f-acore: 0.6907\n",
            "Test:  loss: 0.5894 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7264 | accuracy: 0.4940 | f1: 0.4724\n",
            "Epoch 00114\n",
            "Train: loss: 0.5931 | accuracy: 0.6882 | f-acore: 0.6812\n",
            "Test:  loss: 0.5978 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7254 | accuracy: 0.5060 | f1: 0.4763\n",
            "Epoch 00115\n",
            "Train: loss: 0.5914 | accuracy: 0.6782 | f-acore: 0.6699\n",
            "Test:  loss: 0.5900 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7223 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00116\n",
            "Train: loss: 0.5844 | accuracy: 0.6968 | f-acore: 0.6952\n",
            "Test:  loss: 0.5874 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7289 | accuracy: 0.4702 | f1: 0.4582\n",
            "Epoch 00117\n",
            "Train: loss: 0.5835 | accuracy: 0.6810 | f-acore: 0.6790\n",
            "Test:  loss: 0.5951 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7297 | accuracy: 0.5030 | f1: 0.4784\n",
            "Epoch 00118\n",
            "Train: loss: 0.5813 | accuracy: 0.6911 | f-acore: 0.6811\n",
            "Test:  loss: 0.6111 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7350 | accuracy: 0.5060 | f1: 0.4659\n",
            "Epoch 00119\n",
            "Train: loss: 0.5832 | accuracy: 0.6983 | f-acore: 0.6897\n",
            "Test:  loss: 0.5984 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7293 | accuracy: 0.5089 | f1: 0.4832\n",
            "Epoch 00120\n",
            "Train: loss: 0.5766 | accuracy: 0.6825 | f-acore: 0.6793\n",
            "Test:  loss: 0.5824 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7339 | accuracy: 0.4673 | f1: 0.4607\n",
            "Epoch 00121\n",
            "Train: loss: 0.5760 | accuracy: 0.6968 | f-acore: 0.6943\n",
            "Test:  loss: 0.5868 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7311 | accuracy: 0.5000 | f1: 0.4799\n",
            "Epoch 00122\n",
            "Train: loss: 0.5673 | accuracy: 0.7126 | f-acore: 0.7063\n",
            "Test:  loss: 0.5991 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7355 | accuracy: 0.4970 | f1: 0.4676\n",
            "Epoch 00123\n",
            "Train: loss: 0.5728 | accuracy: 0.6940 | f-acore: 0.6884\n",
            "Test:  loss: 0.5995 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7365 | accuracy: 0.4911 | f1: 0.4713\n",
            "Epoch 00124\n",
            "Train: loss: 0.5740 | accuracy: 0.6983 | f-acore: 0.6962\n",
            "Test:  loss: 0.6038 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7439 | accuracy: 0.4851 | f1: 0.4664\n",
            "Epoch 00125\n",
            "Train: loss: 0.5669 | accuracy: 0.6897 | f-acore: 0.6876\n",
            "Test:  loss: 0.5926 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7396 | accuracy: 0.4821 | f1: 0.4662\n",
            "Epoch 00126\n",
            "Train: loss: 0.5731 | accuracy: 0.7055 | f-acore: 0.7020\n",
            "Test:  loss: 0.5921 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7404 | accuracy: 0.4881 | f1: 0.4701\n",
            "Epoch 00127\n",
            "Train: loss: 0.5640 | accuracy: 0.7112 | f-acore: 0.7074\n",
            "Test:  loss: 0.5992 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7443 | accuracy: 0.4911 | f1: 0.4700\n",
            "Epoch 00128\n",
            "Train: loss: 0.5764 | accuracy: 0.7040 | f-acore: 0.6967\n",
            "Test:  loss: 0.6091 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7396 | accuracy: 0.4911 | f1: 0.4687\n",
            "Epoch 00129\n",
            "Train: loss: 0.5600 | accuracy: 0.7170 | f-acore: 0.7111\n",
            "Test:  loss: 0.6042 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7404 | accuracy: 0.4851 | f1: 0.4664\n",
            "Epoch 00130\n",
            "Train: loss: 0.5567 | accuracy: 0.6954 | f-acore: 0.6926\n",
            "Test:  loss: 0.6022 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7376 | accuracy: 0.4821 | f1: 0.4694\n",
            "Epoch 00131\n",
            "Train: loss: 0.5617 | accuracy: 0.7011 | f-acore: 0.6984\n",
            "Test:  loss: 0.6252 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7398 | accuracy: 0.4762 | f1: 0.4589\n",
            "Epoch 00132\n",
            "Train: loss: 0.5564 | accuracy: 0.7184 | f-acore: 0.7132\n",
            "Test:  loss: 0.6165 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7372 | accuracy: 0.4732 | f1: 0.4587\n",
            "Epoch 00133\n",
            "Train: loss: 0.5515 | accuracy: 0.7170 | f-acore: 0.7134\n",
            "Test:  loss: 0.6113 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7404 | accuracy: 0.4821 | f1: 0.4662\n",
            "Epoch 00134\n",
            "Train: loss: 0.5685 | accuracy: 0.7011 | f-acore: 0.6958\n",
            "Test:  loss: 0.6072 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7484 | accuracy: 0.4911 | f1: 0.4713\n",
            "Epoch 00135\n",
            "Train: loss: 0.5484 | accuracy: 0.7126 | f-acore: 0.7090\n",
            "Test:  loss: 0.6193 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7503 | accuracy: 0.4792 | f1: 0.4548\n",
            "Epoch 00136\n",
            "Train: loss: 0.5637 | accuracy: 0.7011 | f-acore: 0.6938\n",
            "Test:  loss: 0.6390 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7564 | accuracy: 0.5000 | f1: 0.4649\n",
            "Epoch 00137\n",
            "Train: loss: 0.5537 | accuracy: 0.7141 | f-acore: 0.7077\n",
            "Test:  loss: 0.6221 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7536 | accuracy: 0.4792 | f1: 0.4589\n",
            "Epoch 00138\n",
            "Train: loss: 0.5427 | accuracy: 0.7241 | f-acore: 0.7201\n",
            "Test:  loss: 0.6056 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7503 | accuracy: 0.4702 | f1: 0.4592\n",
            "Epoch 00139\n",
            "Train: loss: 0.5625 | accuracy: 0.7098 | f-acore: 0.7071\n",
            "Test:  loss: 0.6142 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7535 | accuracy: 0.4732 | f1: 0.4598\n",
            "Epoch 00140\n",
            "Train: loss: 0.5516 | accuracy: 0.7098 | f-acore: 0.7059\n",
            "Test:  loss: 0.6205 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7596 | accuracy: 0.4792 | f1: 0.4637\n",
            "Epoch 00141\n",
            "Train: loss: 0.5582 | accuracy: 0.7141 | f-acore: 0.7114\n",
            "Test:  loss: 0.6221 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7578 | accuracy: 0.4821 | f1: 0.4639\n",
            "Epoch 00142\n",
            "Train: loss: 0.5496 | accuracy: 0.7141 | f-acore: 0.7087\n",
            "Test:  loss: 0.6319 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7622 | accuracy: 0.4851 | f1: 0.4651\n",
            "Epoch 00143\n",
            "Train: loss: 0.5375 | accuracy: 0.7213 | f-acore: 0.7156\n",
            "Test:  loss: 0.6402 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7598 | accuracy: 0.4762 | f1: 0.4538\n",
            "Epoch 00144\n",
            "Train: loss: 0.5414 | accuracy: 0.7299 | f-acore: 0.7237\n",
            "Test:  loss: 0.6388 | accuracy: 0.7083 | f1: 0.6812\n",
            "Validation:  loss: 0.7654 | accuracy: 0.4643 | f1: 0.4454\n",
            "Epoch 00145\n",
            "Train: loss: 0.5346 | accuracy: 0.7256 | f-acore: 0.7222\n",
            "Test:  loss: 0.6303 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7637 | accuracy: 0.4673 | f1: 0.4526\n",
            "Epoch 00146\n",
            "Train: loss: 0.5331 | accuracy: 0.7112 | f-acore: 0.7072\n",
            "Test:  loss: 0.6368 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7620 | accuracy: 0.4732 | f1: 0.4576\n",
            "Epoch 00147\n",
            "Train: loss: 0.5484 | accuracy: 0.7241 | f-acore: 0.7194\n",
            "Test:  loss: 0.6242 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7616 | accuracy: 0.4643 | f1: 0.4566\n",
            "Epoch 00148\n",
            "Train: loss: 0.5458 | accuracy: 0.7098 | f-acore: 0.7079\n",
            "Test:  loss: 0.6216 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7488 | accuracy: 0.4732 | f1: 0.4653\n",
            "Epoch 00149\n",
            "Train: loss: 0.5392 | accuracy: 0.7112 | f-acore: 0.7095\n",
            "Test:  loss: 0.6450 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7565 | accuracy: 0.4702 | f1: 0.4582\n",
            "Epoch 00150\n",
            "Train: loss: 0.5507 | accuracy: 0.7184 | f-acore: 0.7127\n",
            "Test:  loss: 0.6668 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7775 | accuracy: 0.4702 | f1: 0.4490\n",
            "Epoch 00151\n",
            "Train: loss: 0.5375 | accuracy: 0.7270 | f-acore: 0.7210\n",
            "Test:  loss: 0.6624 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7723 | accuracy: 0.4702 | f1: 0.4540\n",
            "Epoch 00152\n",
            "Train: loss: 0.5418 | accuracy: 0.7184 | f-acore: 0.7166\n",
            "Test:  loss: 0.6556 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7765 | accuracy: 0.4583 | f1: 0.4513\n",
            "Epoch 00153\n",
            "Train: loss: 0.5259 | accuracy: 0.7428 | f-acore: 0.7413\n",
            "Test:  loss: 0.6435 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7680 | accuracy: 0.4643 | f1: 0.4587\n",
            "Epoch 00154\n",
            "Train: loss: 0.5396 | accuracy: 0.7112 | f-acore: 0.7080\n",
            "Test:  loss: 0.6467 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7793 | accuracy: 0.4613 | f1: 0.4506\n",
            "Epoch 00155\n",
            "Train: loss: 0.5244 | accuracy: 0.7514 | f-acore: 0.7491\n",
            "Test:  loss: 0.6480 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7762 | accuracy: 0.4583 | f1: 0.4470\n",
            "Epoch 00156\n",
            "Train: loss: 0.5397 | accuracy: 0.7399 | f-acore: 0.7369\n",
            "Test:  loss: 0.6751 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7735 | accuracy: 0.4673 | f1: 0.4526\n",
            "Epoch 00157\n",
            "Train: loss: 0.5269 | accuracy: 0.7256 | f-acore: 0.7206\n",
            "Test:  loss: 0.6551 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7802 | accuracy: 0.4673 | f1: 0.4575\n",
            "Epoch 00158\n",
            "Train: loss: 0.5191 | accuracy: 0.7428 | f-acore: 0.7393\n",
            "Test:  loss: 0.6695 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7766 | accuracy: 0.4821 | f1: 0.4714\n",
            "Epoch 00159\n",
            "Train: loss: 0.5234 | accuracy: 0.7342 | f-acore: 0.7294\n",
            "Test:  loss: 0.6750 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7743 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00160\n",
            "Train: loss: 0.5242 | accuracy: 0.7500 | f-acore: 0.7483\n",
            "Test:  loss: 0.6518 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7755 | accuracy: 0.4821 | f1: 0.4790\n",
            "Epoch 00161\n",
            "Train: loss: 0.5220 | accuracy: 0.7213 | f-acore: 0.7197\n",
            "Test:  loss: 0.6683 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7912 | accuracy: 0.4821 | f1: 0.4714\n",
            "Epoch 00162\n",
            "Train: loss: 0.5217 | accuracy: 0.7270 | f-acore: 0.7219\n",
            "Test:  loss: 0.6808 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7949 | accuracy: 0.4792 | f1: 0.4614\n",
            "Epoch 00163\n",
            "Train: loss: 0.5275 | accuracy: 0.7328 | f-acore: 0.7276\n",
            "Test:  loss: 0.6371 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7794 | accuracy: 0.4851 | f1: 0.4795\n",
            "Epoch 00164\n",
            "Train: loss: 0.5102 | accuracy: 0.7328 | f-acore: 0.7310\n",
            "Test:  loss: 0.6450 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.7960 | accuracy: 0.4851 | f1: 0.4807\n",
            "Epoch 00165\n",
            "Train: loss: 0.5179 | accuracy: 0.7399 | f-acore: 0.7374\n",
            "Test:  loss: 0.6863 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7950 | accuracy: 0.4821 | f1: 0.4662\n",
            "Epoch 00166\n",
            "Train: loss: 0.5304 | accuracy: 0.7313 | f-acore: 0.7251\n",
            "Test:  loss: 0.6795 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8071 | accuracy: 0.4792 | f1: 0.4637\n",
            "Epoch 00167\n",
            "Train: loss: 0.5214 | accuracy: 0.7457 | f-acore: 0.7430\n",
            "Test:  loss: 0.6525 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7967 | accuracy: 0.4851 | f1: 0.4781\n",
            "Epoch 00168\n",
            "Train: loss: 0.5189 | accuracy: 0.7414 | f-acore: 0.7389\n",
            "Test:  loss: 0.6586 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7918 | accuracy: 0.4821 | f1: 0.4754\n",
            "Epoch 00169\n",
            "Train: loss: 0.5048 | accuracy: 0.7586 | f-acore: 0.7560\n",
            "Test:  loss: 0.6664 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7980 | accuracy: 0.4970 | f1: 0.4886\n",
            "Epoch 00170\n",
            "Train: loss: 0.5177 | accuracy: 0.7356 | f-acore: 0.7331\n",
            "Test:  loss: 0.6822 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7935 | accuracy: 0.4911 | f1: 0.4800\n",
            "Epoch 00171\n",
            "Train: loss: 0.5303 | accuracy: 0.7284 | f-acore: 0.7254\n",
            "Test:  loss: 0.6803 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8062 | accuracy: 0.4970 | f1: 0.4878\n",
            "Epoch 00172\n",
            "Train: loss: 0.5032 | accuracy: 0.7500 | f-acore: 0.7480\n",
            "Test:  loss: 0.6741 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7901 | accuracy: 0.4881 | f1: 0.4807\n",
            "Epoch 00173\n",
            "Train: loss: 0.5094 | accuracy: 0.7385 | f-acore: 0.7360\n",
            "Test:  loss: 0.6716 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7966 | accuracy: 0.4911 | f1: 0.4800\n",
            "Epoch 00174\n",
            "Train: loss: 0.5058 | accuracy: 0.7500 | f-acore: 0.7468\n",
            "Test:  loss: 0.6711 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8040 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00175\n",
            "Train: loss: 0.5037 | accuracy: 0.7457 | f-acore: 0.7438\n",
            "Test:  loss: 0.6622 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.7974 | accuracy: 0.4792 | f1: 0.4775\n",
            "Epoch 00176\n",
            "Train: loss: 0.4970 | accuracy: 0.7644 | f-acore: 0.7627\n",
            "Test:  loss: 0.6872 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8082 | accuracy: 0.4911 | f1: 0.4841\n",
            "Epoch 00177\n",
            "Train: loss: 0.4987 | accuracy: 0.7500 | f-acore: 0.7456\n",
            "Test:  loss: 0.6906 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8036 | accuracy: 0.4851 | f1: 0.4773\n",
            "Epoch 00178\n",
            "Train: loss: 0.4989 | accuracy: 0.7629 | f-acore: 0.7598\n",
            "Test:  loss: 0.6803 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8125 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00179\n",
            "Train: loss: 0.5127 | accuracy: 0.7500 | f-acore: 0.7465\n",
            "Test:  loss: 0.6833 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8184 | accuracy: 0.4762 | f1: 0.4708\n",
            "Epoch 00180\n",
            "Train: loss: 0.5042 | accuracy: 0.7486 | f-acore: 0.7471\n",
            "Test:  loss: 0.6732 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8089 | accuracy: 0.4554 | f1: 0.4550\n",
            "Epoch 00181\n",
            "Train: loss: 0.5217 | accuracy: 0.7629 | f-acore: 0.7613\n",
            "Test:  loss: 0.6844 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8063 | accuracy: 0.4702 | f1: 0.4670\n",
            "Epoch 00182\n",
            "Train: loss: 0.4908 | accuracy: 0.7629 | f-acore: 0.7612\n",
            "Test:  loss: 0.6774 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8025 | accuracy: 0.4911 | f1: 0.4848\n",
            "Epoch 00183\n",
            "Train: loss: 0.4948 | accuracy: 0.7529 | f-acore: 0.7502\n",
            "Test:  loss: 0.6849 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8170 | accuracy: 0.5000 | f1: 0.4921\n",
            "Epoch 00184\n",
            "Train: loss: 0.4969 | accuracy: 0.7543 | f-acore: 0.7523\n",
            "Test:  loss: 0.6840 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8115 | accuracy: 0.4851 | f1: 0.4773\n",
            "Epoch 00185\n",
            "Train: loss: 0.5122 | accuracy: 0.7644 | f-acore: 0.7620\n",
            "Test:  loss: 0.6980 | accuracy: 0.7500 | f1: 0.7188\n",
            "Validation:  loss: 0.8145 | accuracy: 0.5030 | f1: 0.4903\n",
            "Epoch 00186\n",
            "Train: loss: 0.4971 | accuracy: 0.7759 | f-acore: 0.7722\n",
            "Test:  loss: 0.6698 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8093 | accuracy: 0.4762 | f1: 0.4708\n",
            "Epoch 00187\n",
            "Train: loss: 0.4973 | accuracy: 0.7701 | f-acore: 0.7678\n",
            "Test:  loss: 0.6610 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8055 | accuracy: 0.4851 | f1: 0.4823\n",
            "Epoch 00188\n",
            "Train: loss: 0.5015 | accuracy: 0.7529 | f-acore: 0.7508\n",
            "Test:  loss: 0.6786 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8099 | accuracy: 0.4821 | f1: 0.4754\n",
            "Epoch 00189\n",
            "Train: loss: 0.4805 | accuracy: 0.7888 | f-acore: 0.7869\n",
            "Test:  loss: 0.6968 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8252 | accuracy: 0.4940 | f1: 0.4852\n",
            "Epoch 00190\n",
            "Train: loss: 0.5040 | accuracy: 0.7514 | f-acore: 0.7495\n",
            "Test:  loss: 0.6579 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8177 | accuracy: 0.4851 | f1: 0.4827\n",
            "Epoch 00191\n",
            "Train: loss: 0.4897 | accuracy: 0.7701 | f-acore: 0.7686\n",
            "Test:  loss: 0.6693 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8082 | accuracy: 0.4940 | f1: 0.4900\n",
            "Epoch 00192\n",
            "Train: loss: 0.4893 | accuracy: 0.7586 | f-acore: 0.7560\n",
            "Test:  loss: 0.6814 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8302 | accuracy: 0.5000 | f1: 0.4942\n",
            "Epoch 00193\n",
            "Train: loss: 0.4943 | accuracy: 0.7586 | f-acore: 0.7562\n",
            "Test:  loss: 0.6538 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8201 | accuracy: 0.5030 | f1: 0.5002\n",
            "Epoch 00194\n",
            "Train: loss: 0.4807 | accuracy: 0.7629 | f-acore: 0.7606\n",
            "Test:  loss: 0.6596 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8316 | accuracy: 0.4911 | f1: 0.4855\n",
            "Epoch 00195\n",
            "Train: loss: 0.4749 | accuracy: 0.7874 | f-acore: 0.7858\n",
            "Test:  loss: 0.6554 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8236 | accuracy: 0.4792 | f1: 0.4771\n",
            "Epoch 00196\n",
            "Train: loss: 0.4732 | accuracy: 0.7601 | f-acore: 0.7581\n",
            "Test:  loss: 0.6699 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8302 | accuracy: 0.4792 | f1: 0.4758\n",
            "Epoch 00197\n",
            "Train: loss: 0.4730 | accuracy: 0.7802 | f-acore: 0.7779\n",
            "Test:  loss: 0.6817 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8484 | accuracy: 0.4940 | f1: 0.4888\n",
            "Epoch 00198\n",
            "Train: loss: 0.4839 | accuracy: 0.7629 | f-acore: 0.7604\n",
            "Test:  loss: 0.6651 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8392 | accuracy: 0.4851 | f1: 0.4823\n",
            "Epoch 00199\n",
            "Train: loss: 0.5022 | accuracy: 0.7443 | f-acore: 0.7416\n",
            "Test:  loss: 0.6526 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8297 | accuracy: 0.4821 | f1: 0.4807\n",
            "Epoch 00200\n",
            "Train: loss: 0.4723 | accuracy: 0.7773 | f-acore: 0.7764\n",
            "Test:  loss: 0.6529 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8341 | accuracy: 0.4940 | f1: 0.4915\n",
            "Epoch 00201\n",
            "Train: loss: 0.4794 | accuracy: 0.7672 | f-acore: 0.7657\n",
            "Test:  loss: 0.6705 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8306 | accuracy: 0.4970 | f1: 0.4921\n",
            "Epoch 00202\n",
            "Train: loss: 0.4760 | accuracy: 0.7701 | f-acore: 0.7675\n",
            "Test:  loss: 0.7017 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8509 | accuracy: 0.4940 | f1: 0.4882\n",
            "Epoch 00203\n",
            "Train: loss: 0.4657 | accuracy: 0.7744 | f-acore: 0.7721\n",
            "Test:  loss: 0.6621 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8480 | accuracy: 0.4732 | f1: 0.4724\n",
            "Epoch 00204\n",
            "Train: loss: 0.4973 | accuracy: 0.7601 | f-acore: 0.7591\n",
            "Test:  loss: 0.6346 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8535 | accuracy: 0.4732 | f1: 0.4722\n",
            "Epoch 00205\n",
            "Train: loss: 0.4732 | accuracy: 0.7658 | f-acore: 0.7641\n",
            "Test:  loss: 0.6992 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8530 | accuracy: 0.4911 | f1: 0.4818\n",
            "Epoch 00206\n",
            "Train: loss: 0.4815 | accuracy: 0.7787 | f-acore: 0.7753\n",
            "Test:  loss: 0.6777 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8481 | accuracy: 0.4940 | f1: 0.4868\n",
            "Epoch 00207\n",
            "Train: loss: 0.4693 | accuracy: 0.7859 | f-acore: 0.7842\n",
            "Test:  loss: 0.6730 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8399 | accuracy: 0.5030 | f1: 0.5002\n",
            "Epoch 00208\n",
            "Train: loss: 0.4560 | accuracy: 0.7658 | f-acore: 0.7642\n",
            "Test:  loss: 0.6766 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8468 | accuracy: 0.4970 | f1: 0.4947\n",
            "Epoch 00209\n",
            "Train: loss: 0.4638 | accuracy: 0.7658 | f-acore: 0.7636\n",
            "Test:  loss: 0.6873 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8471 | accuracy: 0.4970 | f1: 0.4942\n",
            "Epoch 00210\n",
            "Train: loss: 0.4555 | accuracy: 0.7945 | f-acore: 0.7925\n",
            "Test:  loss: 0.6844 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8634 | accuracy: 0.4821 | f1: 0.4803\n",
            "Epoch 00211\n",
            "Train: loss: 0.4705 | accuracy: 0.7845 | f-acore: 0.7835\n",
            "Test:  loss: 0.6975 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8550 | accuracy: 0.4762 | f1: 0.4747\n",
            "Epoch 00212\n",
            "Train: loss: 0.4644 | accuracy: 0.7874 | f-acore: 0.7858\n",
            "Test:  loss: 0.7220 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8582 | accuracy: 0.5030 | f1: 0.4975\n",
            "Epoch 00213\n",
            "Train: loss: 0.4829 | accuracy: 0.7658 | f-acore: 0.7643\n",
            "Test:  loss: 0.7070 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8562 | accuracy: 0.4851 | f1: 0.4827\n",
            "Epoch 00214\n",
            "Train: loss: 0.4559 | accuracy: 0.7687 | f-acore: 0.7674\n",
            "Test:  loss: 0.6962 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8496 | accuracy: 0.4940 | f1: 0.4910\n",
            "Epoch 00215\n",
            "Train: loss: 0.4679 | accuracy: 0.7701 | f-acore: 0.7680\n",
            "Test:  loss: 0.6968 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8538 | accuracy: 0.4911 | f1: 0.4887\n",
            "Epoch 00216\n",
            "Train: loss: 0.4605 | accuracy: 0.7802 | f-acore: 0.7781\n",
            "Test:  loss: 0.7090 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8476 | accuracy: 0.4821 | f1: 0.4810\n",
            "Epoch 00217\n",
            "Train: loss: 0.4559 | accuracy: 0.7744 | f-acore: 0.7738\n",
            "Test:  loss: 0.7233 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8594 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00218\n",
            "Train: loss: 0.4403 | accuracy: 0.7787 | f-acore: 0.7771\n",
            "Test:  loss: 0.7242 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8743 | accuracy: 0.5060 | f1: 0.4996\n",
            "Epoch 00219\n",
            "Train: loss: 0.4694 | accuracy: 0.7744 | f-acore: 0.7708\n",
            "Test:  loss: 0.7205 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8624 | accuracy: 0.5060 | f1: 0.4981\n",
            "Epoch 00220\n",
            "Train: loss: 0.4564 | accuracy: 0.7859 | f-acore: 0.7844\n",
            "Test:  loss: 0.6806 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8728 | accuracy: 0.4881 | f1: 0.4855\n",
            "Epoch 00221\n",
            "Train: loss: 0.4664 | accuracy: 0.7830 | f-acore: 0.7821\n",
            "Test:  loss: 0.6699 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8557 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00222\n",
            "Train: loss: 0.4631 | accuracy: 0.7859 | f-acore: 0.7844\n",
            "Test:  loss: 0.6975 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8545 | accuracy: 0.4970 | f1: 0.4908\n",
            "Epoch 00223\n",
            "Train: loss: 0.4535 | accuracy: 0.7773 | f-acore: 0.7739\n",
            "Test:  loss: 0.6909 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8688 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00224\n",
            "Train: loss: 0.4311 | accuracy: 0.8060 | f-acore: 0.8048\n",
            "Test:  loss: 0.6983 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8698 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00225\n",
            "Train: loss: 0.4639 | accuracy: 0.7917 | f-acore: 0.7905\n",
            "Test:  loss: 0.6757 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8693 | accuracy: 0.4821 | f1: 0.4803\n",
            "Epoch 00226\n",
            "Train: loss: 0.4488 | accuracy: 0.7974 | f-acore: 0.7959\n",
            "Test:  loss: 0.6633 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8615 | accuracy: 0.5000 | f1: 0.4965\n",
            "Epoch 00227\n",
            "Train: loss: 0.4351 | accuracy: 0.7931 | f-acore: 0.7916\n",
            "Test:  loss: 0.6601 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8727 | accuracy: 0.4881 | f1: 0.4850\n",
            "Epoch 00228\n",
            "Train: loss: 0.4550 | accuracy: 0.7888 | f-acore: 0.7869\n",
            "Test:  loss: 0.6898 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8837 | accuracy: 0.4970 | f1: 0.4927\n",
            "Epoch 00229\n",
            "Train: loss: 0.4516 | accuracy: 0.7902 | f-acore: 0.7884\n",
            "Test:  loss: 0.6807 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8704 | accuracy: 0.4702 | f1: 0.4687\n",
            "Epoch 00230\n",
            "Train: loss: 0.4606 | accuracy: 0.7615 | f-acore: 0.7593\n",
            "Test:  loss: 0.6846 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8725 | accuracy: 0.4613 | f1: 0.4602\n",
            "Epoch 00231\n",
            "Train: loss: 0.4534 | accuracy: 0.7874 | f-acore: 0.7867\n",
            "Test:  loss: 0.7066 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8762 | accuracy: 0.4643 | f1: 0.4624\n",
            "Epoch 00232\n",
            "Train: loss: 0.4487 | accuracy: 0.7902 | f-acore: 0.7886\n",
            "Test:  loss: 0.7309 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8720 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00233\n",
            "Train: loss: 0.4340 | accuracy: 0.8103 | f-acore: 0.8088\n",
            "Test:  loss: 0.6975 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8901 | accuracy: 0.4851 | f1: 0.4823\n",
            "Epoch 00234\n",
            "Train: loss: 0.4413 | accuracy: 0.8003 | f-acore: 0.7984\n",
            "Test:  loss: 0.6742 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8743 | accuracy: 0.4702 | f1: 0.4690\n",
            "Epoch 00235\n",
            "Train: loss: 0.4585 | accuracy: 0.7859 | f-acore: 0.7840\n",
            "Test:  loss: 0.6949 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8954 | accuracy: 0.4821 | f1: 0.4790\n",
            "Epoch 00236\n",
            "Train: loss: 0.4211 | accuracy: 0.8046 | f-acore: 0.8036\n",
            "Test:  loss: 0.7080 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8796 | accuracy: 0.4940 | f1: 0.4888\n",
            "Epoch 00237\n",
            "Train: loss: 0.4388 | accuracy: 0.8003 | f-acore: 0.7982\n",
            "Test:  loss: 0.7277 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8990 | accuracy: 0.4970 | f1: 0.4894\n",
            "Epoch 00238\n",
            "Train: loss: 0.4392 | accuracy: 0.7773 | f-acore: 0.7753\n",
            "Test:  loss: 0.6498 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8741 | accuracy: 0.4762 | f1: 0.4757\n",
            "Epoch 00239\n",
            "Train: loss: 0.4230 | accuracy: 0.8147 | f-acore: 0.8141\n",
            "Test:  loss: 0.6744 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8783 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00240\n",
            "Train: loss: 0.4308 | accuracy: 0.8103 | f-acore: 0.8093\n",
            "Test:  loss: 0.7274 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8896 | accuracy: 0.4911 | f1: 0.4873\n",
            "Epoch 00241\n",
            "Train: loss: 0.4381 | accuracy: 0.7888 | f-acore: 0.7854\n",
            "Test:  loss: 0.7217 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9060 | accuracy: 0.5089 | f1: 0.5022\n",
            "Epoch 00242\n",
            "Train: loss: 0.4417 | accuracy: 0.7974 | f-acore: 0.7957\n",
            "Test:  loss: 0.6604 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8901 | accuracy: 0.4792 | f1: 0.4786\n",
            "Epoch 00243\n",
            "Train: loss: 0.4353 | accuracy: 0.7859 | f-acore: 0.7855\n",
            "Test:  loss: 0.6940 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8832 | accuracy: 0.4821 | f1: 0.4795\n",
            "Epoch 00244\n",
            "Train: loss: 0.4336 | accuracy: 0.7845 | f-acore: 0.7819\n",
            "Test:  loss: 0.7347 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8885 | accuracy: 0.4702 | f1: 0.4665\n",
            "Epoch 00245\n",
            "Train: loss: 0.4325 | accuracy: 0.8032 | f-acore: 0.8013\n",
            "Test:  loss: 0.7101 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8750 | accuracy: 0.4792 | f1: 0.4771\n",
            "Epoch 00246\n",
            "Train: loss: 0.4416 | accuracy: 0.8003 | f-acore: 0.7990\n",
            "Test:  loss: 0.7229 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8965 | accuracy: 0.4792 | f1: 0.4767\n",
            "Epoch 00247\n",
            "Train: loss: 0.4241 | accuracy: 0.8003 | f-acore: 0.7989\n",
            "Test:  loss: 0.6919 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8794 | accuracy: 0.4792 | f1: 0.4778\n",
            "Epoch 00248\n",
            "Train: loss: 0.4465 | accuracy: 0.7960 | f-acore: 0.7954\n",
            "Test:  loss: 0.6608 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8860 | accuracy: 0.4792 | f1: 0.4784\n",
            "Epoch 00249\n",
            "Train: loss: 0.4418 | accuracy: 0.8032 | f-acore: 0.8025\n",
            "Test:  loss: 0.7182 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8870 | accuracy: 0.5000 | f1: 0.4960\n",
            "Epoch 00250\n",
            "Train: loss: 0.4399 | accuracy: 0.7845 | f-acore: 0.7824\n",
            "Test:  loss: 0.7198 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8878 | accuracy: 0.4940 | f1: 0.4900\n",
            "Epoch 00251\n",
            "Train: loss: 0.4347 | accuracy: 0.8032 | f-acore: 0.8012\n",
            "Test:  loss: 0.6810 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8932 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00252\n",
            "Train: loss: 0.4434 | accuracy: 0.8032 | f-acore: 0.8013\n",
            "Test:  loss: 0.7042 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8998 | accuracy: 0.4911 | f1: 0.4882\n",
            "Epoch 00253\n",
            "Train: loss: 0.4374 | accuracy: 0.7960 | f-acore: 0.7943\n",
            "Test:  loss: 0.7424 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9070 | accuracy: 0.5030 | f1: 0.4975\n",
            "Epoch 00254\n",
            "Train: loss: 0.4142 | accuracy: 0.8247 | f-acore: 0.8239\n",
            "Test:  loss: 0.7234 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8906 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00255\n",
            "Train: loss: 0.4189 | accuracy: 0.8032 | f-acore: 0.8020\n",
            "Test:  loss: 0.7596 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8978 | accuracy: 0.4911 | f1: 0.4887\n",
            "Epoch 00256\n",
            "Train: loss: 0.4524 | accuracy: 0.7931 | f-acore: 0.7917\n",
            "Test:  loss: 0.7118 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9011 | accuracy: 0.4792 | f1: 0.4767\n",
            "Epoch 00257\n",
            "Train: loss: 0.4477 | accuracy: 0.7931 | f-acore: 0.7909\n",
            "Test:  loss: 0.7144 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8931 | accuracy: 0.4732 | f1: 0.4707\n",
            "Epoch 00258\n",
            "Train: loss: 0.4194 | accuracy: 0.8003 | f-acore: 0.7983\n",
            "Test:  loss: 0.7134 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.8979 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00259\n",
            "Train: loss: 0.4352 | accuracy: 0.8060 | f-acore: 0.8050\n",
            "Test:  loss: 0.7232 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9076 | accuracy: 0.4821 | f1: 0.4803\n",
            "Epoch 00260\n",
            "Train: loss: 0.4227 | accuracy: 0.8261 | f-acore: 0.8246\n",
            "Test:  loss: 0.6918 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9008 | accuracy: 0.4792 | f1: 0.4781\n",
            "Epoch 00261\n",
            "Train: loss: 0.4202 | accuracy: 0.8032 | f-acore: 0.8025\n",
            "Test:  loss: 0.7007 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9142 | accuracy: 0.4762 | f1: 0.4747\n",
            "Epoch 00262\n",
            "Train: loss: 0.4069 | accuracy: 0.8175 | f-acore: 0.8160\n",
            "Test:  loss: 0.7520 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9013 | accuracy: 0.4851 | f1: 0.4807\n",
            "Epoch 00263\n",
            "Train: loss: 0.4366 | accuracy: 0.8075 | f-acore: 0.8053\n",
            "Test:  loss: 0.7255 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9177 | accuracy: 0.4821 | f1: 0.4799\n",
            "Epoch 00264\n",
            "Train: loss: 0.4273 | accuracy: 0.7960 | f-acore: 0.7952\n",
            "Test:  loss: 0.6955 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9008 | accuracy: 0.4821 | f1: 0.4812\n",
            "Epoch 00265\n",
            "Train: loss: 0.4189 | accuracy: 0.8060 | f-acore: 0.8058\n",
            "Test:  loss: 0.7397 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9150 | accuracy: 0.4702 | f1: 0.4684\n",
            "Epoch 00266\n",
            "Train: loss: 0.4274 | accuracy: 0.7989 | f-acore: 0.7972\n",
            "Test:  loss: 0.7624 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.8978 | accuracy: 0.4821 | f1: 0.4795\n",
            "Epoch 00267\n",
            "Train: loss: 0.4447 | accuracy: 0.8046 | f-acore: 0.8030\n",
            "Test:  loss: 0.7262 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9193 | accuracy: 0.4762 | f1: 0.4743\n",
            "Epoch 00268\n",
            "Train: loss: 0.3985 | accuracy: 0.8190 | f-acore: 0.8183\n",
            "Test:  loss: 0.7222 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9122 | accuracy: 0.4792 | f1: 0.4771\n",
            "Epoch 00269\n",
            "Train: loss: 0.4054 | accuracy: 0.8161 | f-acore: 0.8143\n",
            "Test:  loss: 0.7655 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9096 | accuracy: 0.4970 | f1: 0.4921\n",
            "Epoch 00270\n",
            "Train: loss: 0.4326 | accuracy: 0.8147 | f-acore: 0.8129\n",
            "Test:  loss: 0.7272 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9191 | accuracy: 0.4673 | f1: 0.4667\n",
            "Epoch 00271\n",
            "Train: loss: 0.4102 | accuracy: 0.8103 | f-acore: 0.8091\n",
            "Test:  loss: 0.7066 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9190 | accuracy: 0.4762 | f1: 0.4755\n",
            "Epoch 00272\n",
            "Train: loss: 0.4078 | accuracy: 0.8075 | f-acore: 0.8066\n",
            "Test:  loss: 0.7108 | accuracy: 0.7083 | f1: 0.6951\n",
            "Validation:  loss: 0.9250 | accuracy: 0.4702 | f1: 0.4693\n",
            "Epoch 00273\n",
            "Train: loss: 0.4189 | accuracy: 0.8103 | f-acore: 0.8084\n",
            "Test:  loss: 0.7335 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9174 | accuracy: 0.4732 | f1: 0.4724\n",
            "Epoch 00274\n",
            "Train: loss: 0.4243 | accuracy: 0.8132 | f-acore: 0.8119\n",
            "Test:  loss: 0.7203 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9074 | accuracy: 0.4821 | f1: 0.4817\n",
            "Epoch 00275\n",
            "Train: loss: 0.4133 | accuracy: 0.8017 | f-acore: 0.8004\n",
            "Test:  loss: 0.7328 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9228 | accuracy: 0.4821 | f1: 0.4815\n",
            "Epoch 00276\n",
            "Train: loss: 0.4038 | accuracy: 0.8032 | f-acore: 0.8013\n",
            "Test:  loss: 0.7362 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9114 | accuracy: 0.4702 | f1: 0.4670\n",
            "Epoch 00277\n",
            "Train: loss: 0.3973 | accuracy: 0.8348 | f-acore: 0.8332\n",
            "Test:  loss: 0.7204 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9210 | accuracy: 0.4792 | f1: 0.4786\n",
            "Epoch 00278\n",
            "Train: loss: 0.4002 | accuracy: 0.8089 | f-acore: 0.8082\n",
            "Test:  loss: 0.7083 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9299 | accuracy: 0.4762 | f1: 0.4761\n",
            "Epoch 00279\n",
            "Train: loss: 0.4133 | accuracy: 0.8147 | f-acore: 0.8135\n",
            "Test:  loss: 0.7078 | accuracy: 0.6667 | f1: 0.6571\n",
            "Validation:  loss: 0.9244 | accuracy: 0.4702 | f1: 0.4702\n",
            "Epoch 00280\n",
            "Train: loss: 0.4202 | accuracy: 0.7960 | f-acore: 0.7950\n",
            "Test:  loss: 0.7301 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9244 | accuracy: 0.4732 | f1: 0.4730\n",
            "Epoch 00281\n",
            "Train: loss: 0.4126 | accuracy: 0.8017 | f-acore: 0.8008\n",
            "Test:  loss: 0.7436 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9290 | accuracy: 0.4762 | f1: 0.4757\n",
            "Epoch 00282\n",
            "Train: loss: 0.4024 | accuracy: 0.8290 | f-acore: 0.8281\n",
            "Test:  loss: 0.7364 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9309 | accuracy: 0.4732 | f1: 0.4722\n",
            "Epoch 00283\n",
            "Train: loss: 0.4044 | accuracy: 0.8103 | f-acore: 0.8093\n",
            "Test:  loss: 0.7431 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9349 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00284\n",
            "Train: loss: 0.3928 | accuracy: 0.8218 | f-acore: 0.8215\n",
            "Test:  loss: 0.7706 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9539 | accuracy: 0.4702 | f1: 0.4699\n",
            "Epoch 00285\n",
            "Train: loss: 0.3977 | accuracy: 0.8190 | f-acore: 0.8181\n",
            "Test:  loss: 0.7571 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9414 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00286\n",
            "Train: loss: 0.4175 | accuracy: 0.8147 | f-acore: 0.8130\n",
            "Test:  loss: 0.7173 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9266 | accuracy: 0.4702 | f1: 0.4696\n",
            "Epoch 00287\n",
            "Train: loss: 0.4158 | accuracy: 0.8046 | f-acore: 0.8030\n",
            "Test:  loss: 0.7272 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9389 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00288\n",
            "Train: loss: 0.3984 | accuracy: 0.8161 | f-acore: 0.8152\n",
            "Test:  loss: 0.7526 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9170 | accuracy: 0.4762 | f1: 0.4755\n",
            "Epoch 00289\n",
            "Train: loss: 0.3915 | accuracy: 0.8463 | f-acore: 0.8455\n",
            "Test:  loss: 0.7821 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9197 | accuracy: 0.4762 | f1: 0.4720\n",
            "Epoch 00290\n",
            "Train: loss: 0.4025 | accuracy: 0.8103 | f-acore: 0.8086\n",
            "Test:  loss: 0.7571 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9318 | accuracy: 0.4702 | f1: 0.4690\n",
            "Epoch 00291\n",
            "Train: loss: 0.4022 | accuracy: 0.8132 | f-acore: 0.8113\n",
            "Test:  loss: 0.7526 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9351 | accuracy: 0.4673 | f1: 0.4659\n",
            "Epoch 00292\n",
            "Train: loss: 0.3945 | accuracy: 0.8204 | f-acore: 0.8191\n",
            "Test:  loss: 0.7348 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9307 | accuracy: 0.4702 | f1: 0.4699\n",
            "Epoch 00293\n",
            "Train: loss: 0.3946 | accuracy: 0.8319 | f-acore: 0.8317\n",
            "Test:  loss: 0.7473 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9452 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00294\n",
            "Train: loss: 0.3906 | accuracy: 0.8233 | f-acore: 0.8220\n",
            "Test:  loss: 0.7616 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9396 | accuracy: 0.4702 | f1: 0.4699\n",
            "Epoch 00295\n",
            "Train: loss: 0.3904 | accuracy: 0.8103 | f-acore: 0.8094\n",
            "Test:  loss: 0.7435 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9465 | accuracy: 0.4673 | f1: 0.4669\n",
            "Epoch 00296\n",
            "Train: loss: 0.3879 | accuracy: 0.8147 | f-acore: 0.8134\n",
            "Test:  loss: 0.7438 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9442 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00297\n",
            "Train: loss: 0.4062 | accuracy: 0.8103 | f-acore: 0.8093\n",
            "Test:  loss: 0.7682 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9571 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00298\n",
            "Train: loss: 0.4016 | accuracy: 0.8204 | f-acore: 0.8190\n",
            "Test:  loss: 0.7798 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9578 | accuracy: 0.4702 | f1: 0.4701\n",
            "Epoch 00299\n",
            "Train: loss: 0.3899 | accuracy: 0.8161 | f-acore: 0.8149\n",
            "Test:  loss: 0.7927 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9620 | accuracy: 0.4702 | f1: 0.4698\n",
            "Epoch 00300\n",
            "Train: loss: 0.3621 | accuracy: 0.8376 | f-acore: 0.8371\n",
            "Test:  loss: 0.7785 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9615 | accuracy: 0.4702 | f1: 0.4690\n",
            "Epoch 00301\n",
            "Train: loss: 0.4010 | accuracy: 0.8247 | f-acore: 0.8230\n",
            "Test:  loss: 0.7447 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9652 | accuracy: 0.4792 | f1: 0.4791\n",
            "Epoch 00302\n",
            "Train: loss: 0.3867 | accuracy: 0.8362 | f-acore: 0.8356\n",
            "Test:  loss: 0.7411 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9576 | accuracy: 0.4821 | f1: 0.4817\n",
            "Epoch 00303\n",
            "Train: loss: 0.3707 | accuracy: 0.8319 | f-acore: 0.8308\n",
            "Test:  loss: 0.7790 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9718 | accuracy: 0.4732 | f1: 0.4711\n",
            "Epoch 00304\n",
            "Train: loss: 0.3823 | accuracy: 0.8333 | f-acore: 0.8321\n",
            "Test:  loss: 0.7923 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9611 | accuracy: 0.4821 | f1: 0.4799\n",
            "Epoch 00305\n",
            "Train: loss: 0.4006 | accuracy: 0.8089 | f-acore: 0.8079\n",
            "Test:  loss: 0.7737 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9881 | accuracy: 0.4732 | f1: 0.4732\n",
            "Epoch 00306\n",
            "Train: loss: 0.3992 | accuracy: 0.8060 | f-acore: 0.8055\n",
            "Test:  loss: 0.8004 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9575 | accuracy: 0.4792 | f1: 0.4788\n",
            "Epoch 00307\n",
            "Train: loss: 0.3824 | accuracy: 0.8290 | f-acore: 0.8275\n",
            "Test:  loss: 0.7904 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9618 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00308\n",
            "Train: loss: 0.3672 | accuracy: 0.8463 | f-acore: 0.8449\n",
            "Test:  loss: 0.7903 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9624 | accuracy: 0.4732 | f1: 0.4728\n",
            "Epoch 00309\n",
            "Train: loss: 0.3784 | accuracy: 0.8147 | f-acore: 0.8139\n",
            "Test:  loss: 0.7796 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9704 | accuracy: 0.4792 | f1: 0.4791\n",
            "Epoch 00310\n",
            "Train: loss: 0.3897 | accuracy: 0.8089 | f-acore: 0.8082\n",
            "Test:  loss: 0.7845 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9686 | accuracy: 0.4732 | f1: 0.4726\n",
            "Epoch 00311\n",
            "Train: loss: 0.3814 | accuracy: 0.8247 | f-acore: 0.8237\n",
            "Test:  loss: 0.7989 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9641 | accuracy: 0.4732 | f1: 0.4719\n",
            "Epoch 00312\n",
            "Train: loss: 0.3670 | accuracy: 0.8233 | f-acore: 0.8220\n",
            "Test:  loss: 0.8019 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9683 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00313\n",
            "Train: loss: 0.3785 | accuracy: 0.8233 | f-acore: 0.8228\n",
            "Test:  loss: 0.7941 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9597 | accuracy: 0.4702 | f1: 0.4693\n",
            "Epoch 00314\n",
            "Train: loss: 0.3697 | accuracy: 0.8534 | f-acore: 0.8524\n",
            "Test:  loss: 0.8173 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9678 | accuracy: 0.4702 | f1: 0.4684\n",
            "Epoch 00315\n",
            "Train: loss: 0.3604 | accuracy: 0.8420 | f-acore: 0.8412\n",
            "Test:  loss: 0.8092 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9758 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00316\n",
            "Train: loss: 0.3874 | accuracy: 0.8290 | f-acore: 0.8275\n",
            "Test:  loss: 0.7882 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9873 | accuracy: 0.4702 | f1: 0.4684\n",
            "Epoch 00317\n",
            "Train: loss: 0.3846 | accuracy: 0.8319 | f-acore: 0.8310\n",
            "Test:  loss: 0.7707 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9885 | accuracy: 0.4732 | f1: 0.4726\n",
            "Epoch 00318\n",
            "Train: loss: 0.3780 | accuracy: 0.8477 | f-acore: 0.8471\n",
            "Test:  loss: 0.7993 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0002 | accuracy: 0.4732 | f1: 0.4726\n",
            "Epoch 00319\n",
            "Train: loss: 0.3915 | accuracy: 0.8348 | f-acore: 0.8334\n",
            "Test:  loss: 0.8152 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9743 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00320\n",
            "Train: loss: 0.3917 | accuracy: 0.8405 | f-acore: 0.8394\n",
            "Test:  loss: 0.7933 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9616 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00321\n",
            "Train: loss: 0.3870 | accuracy: 0.8261 | f-acore: 0.8252\n",
            "Test:  loss: 0.8052 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9787 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00322\n",
            "Train: loss: 0.3843 | accuracy: 0.8405 | f-acore: 0.8396\n",
            "Test:  loss: 0.8232 | accuracy: 0.6250 | f1: 0.5901\n",
            "Validation:  loss: 0.9822 | accuracy: 0.4792 | f1: 0.4784\n",
            "Epoch 00323\n",
            "Train: loss: 0.3723 | accuracy: 0.8463 | f-acore: 0.8454\n",
            "Test:  loss: 0.7902 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9693 | accuracy: 0.4762 | f1: 0.4757\n",
            "Epoch 00324\n",
            "Train: loss: 0.3696 | accuracy: 0.8376 | f-acore: 0.8373\n",
            "Test:  loss: 0.8012 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9932 | accuracy: 0.4792 | f1: 0.4786\n",
            "Epoch 00325\n",
            "Train: loss: 0.3593 | accuracy: 0.8448 | f-acore: 0.8442\n",
            "Test:  loss: 0.8287 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9677 | accuracy: 0.4911 | f1: 0.4891\n",
            "Epoch 00326\n",
            "Train: loss: 0.3641 | accuracy: 0.8448 | f-acore: 0.8441\n",
            "Test:  loss: 0.8278 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9728 | accuracy: 0.4851 | f1: 0.4835\n",
            "Epoch 00327\n",
            "Train: loss: 0.3756 | accuracy: 0.8434 | f-acore: 0.8428\n",
            "Test:  loss: 0.8527 | accuracy: 0.6667 | f1: 0.6444\n",
            "Validation:  loss: 0.9708 | accuracy: 0.4821 | f1: 0.4815\n",
            "Epoch 00328\n",
            "Train: loss: 0.3617 | accuracy: 0.8348 | f-acore: 0.8336\n",
            "Test:  loss: 0.8763 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9776 | accuracy: 0.4792 | f1: 0.4786\n",
            "Epoch 00329\n",
            "Train: loss: 0.3629 | accuracy: 0.8333 | f-acore: 0.8325\n",
            "Test:  loss: 0.8493 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9788 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00330\n",
            "Train: loss: 0.3502 | accuracy: 0.8434 | f-acore: 0.8425\n",
            "Test:  loss: 0.8472 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0034 | accuracy: 0.4792 | f1: 0.4781\n",
            "Epoch 00331\n",
            "Train: loss: 0.3677 | accuracy: 0.8319 | f-acore: 0.8305\n",
            "Test:  loss: 0.8551 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0055 | accuracy: 0.4762 | f1: 0.4760\n",
            "Epoch 00332\n",
            "Train: loss: 0.3804 | accuracy: 0.8319 | f-acore: 0.8311\n",
            "Test:  loss: 0.8294 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9828 | accuracy: 0.4702 | f1: 0.4699\n",
            "Epoch 00333\n",
            "Train: loss: 0.3667 | accuracy: 0.8463 | f-acore: 0.8457\n",
            "Test:  loss: 0.8530 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9795 | accuracy: 0.4911 | f1: 0.4898\n",
            "Epoch 00334\n",
            "Train: loss: 0.3594 | accuracy: 0.8362 | f-acore: 0.8346\n",
            "Test:  loss: 0.8687 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9686 | accuracy: 0.5089 | f1: 0.5066\n",
            "Epoch 00335\n",
            "Train: loss: 0.3525 | accuracy: 0.8434 | f-acore: 0.8419\n",
            "Test:  loss: 0.8250 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0011 | accuracy: 0.4792 | f1: 0.4788\n",
            "Epoch 00336\n",
            "Train: loss: 0.3716 | accuracy: 0.8391 | f-acore: 0.8381\n",
            "Test:  loss: 0.8418 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9859 | accuracy: 0.4851 | f1: 0.4843\n",
            "Epoch 00337\n",
            "Train: loss: 0.3700 | accuracy: 0.8348 | f-acore: 0.8341\n",
            "Test:  loss: 0.7996 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0015 | accuracy: 0.4792 | f1: 0.4786\n",
            "Epoch 00338\n",
            "Train: loss: 0.3692 | accuracy: 0.8333 | f-acore: 0.8327\n",
            "Test:  loss: 0.8351 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9807 | accuracy: 0.4851 | f1: 0.4843\n",
            "Epoch 00339\n",
            "Train: loss: 0.3605 | accuracy: 0.8376 | f-acore: 0.8365\n",
            "Test:  loss: 0.8406 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9911 | accuracy: 0.4821 | f1: 0.4815\n",
            "Epoch 00340\n",
            "Train: loss: 0.3848 | accuracy: 0.8290 | f-acore: 0.8277\n",
            "Test:  loss: 0.8406 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0089 | accuracy: 0.4881 | f1: 0.4866\n",
            "Epoch 00341\n",
            "Train: loss: 0.3862 | accuracy: 0.8147 | f-acore: 0.8134\n",
            "Test:  loss: 0.8419 | accuracy: 0.6250 | f1: 0.5901\n",
            "Validation:  loss: 0.9895 | accuracy: 0.4970 | f1: 0.4947\n",
            "Epoch 00342\n",
            "Train: loss: 0.3679 | accuracy: 0.8261 | f-acore: 0.8245\n",
            "Test:  loss: 0.8444 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9791 | accuracy: 0.4940 | f1: 0.4932\n",
            "Epoch 00343\n",
            "Train: loss: 0.3955 | accuracy: 0.8204 | f-acore: 0.8192\n",
            "Test:  loss: 0.8440 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9868 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00344\n",
            "Train: loss: 0.3527 | accuracy: 0.8463 | f-acore: 0.8457\n",
            "Test:  loss: 0.8417 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9835 | accuracy: 0.4940 | f1: 0.4934\n",
            "Epoch 00345\n",
            "Train: loss: 0.3512 | accuracy: 0.8362 | f-acore: 0.8357\n",
            "Test:  loss: 0.8333 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9988 | accuracy: 0.5030 | f1: 0.5020\n",
            "Epoch 00346\n",
            "Train: loss: 0.3548 | accuracy: 0.8491 | f-acore: 0.8486\n",
            "Test:  loss: 0.8261 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0013 | accuracy: 0.4940 | f1: 0.4932\n",
            "Epoch 00347\n",
            "Train: loss: 0.3554 | accuracy: 0.8376 | f-acore: 0.8365\n",
            "Test:  loss: 0.8618 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 0.9888 | accuracy: 0.4940 | f1: 0.4929\n",
            "Epoch 00348\n",
            "Train: loss: 0.3704 | accuracy: 0.8420 | f-acore: 0.8413\n",
            "Test:  loss: 0.8604 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0030 | accuracy: 0.4970 | f1: 0.4963\n",
            "Epoch 00349\n",
            "Train: loss: 0.3674 | accuracy: 0.8463 | f-acore: 0.8453\n",
            "Test:  loss: 0.8242 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9952 | accuracy: 0.4970 | f1: 0.4965\n",
            "Epoch 00350\n",
            "Train: loss: 0.3592 | accuracy: 0.8333 | f-acore: 0.8326\n",
            "Test:  loss: 0.8354 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9953 | accuracy: 0.4940 | f1: 0.4929\n",
            "Epoch 00351\n",
            "Train: loss: 0.3615 | accuracy: 0.8333 | f-acore: 0.8325\n",
            "Test:  loss: 0.8728 | accuracy: 0.6250 | f1: 0.5901\n",
            "Validation:  loss: 0.9996 | accuracy: 0.5000 | f1: 0.4982\n",
            "Epoch 00352\n",
            "Train: loss: 0.3697 | accuracy: 0.8362 | f-acore: 0.8344\n",
            "Test:  loss: 0.8715 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9874 | accuracy: 0.5000 | f1: 0.4996\n",
            "Epoch 00353\n",
            "Train: loss: 0.3731 | accuracy: 0.8405 | f-acore: 0.8399\n",
            "Test:  loss: 0.8399 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0253 | accuracy: 0.4970 | f1: 0.4965\n",
            "Epoch 00354\n",
            "Train: loss: 0.3594 | accuracy: 0.8463 | f-acore: 0.8456\n",
            "Test:  loss: 0.8321 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0083 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00355\n",
            "Train: loss: 0.3647 | accuracy: 0.8362 | f-acore: 0.8346\n",
            "Test:  loss: 0.8907 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0269 | accuracy: 0.4970 | f1: 0.4921\n",
            "Epoch 00356\n",
            "Train: loss: 0.3726 | accuracy: 0.8506 | f-acore: 0.8490\n",
            "Test:  loss: 0.8306 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0142 | accuracy: 0.4970 | f1: 0.4967\n",
            "Epoch 00357\n",
            "Train: loss: 0.3437 | accuracy: 0.8434 | f-acore: 0.8431\n",
            "Test:  loss: 0.8138 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0202 | accuracy: 0.5000 | f1: 0.4999\n",
            "Epoch 00358\n",
            "Train: loss: 0.3608 | accuracy: 0.8434 | f-acore: 0.8427\n",
            "Test:  loss: 0.8896 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0085 | accuracy: 0.4940 | f1: 0.4929\n",
            "Epoch 00359\n",
            "Train: loss: 0.3420 | accuracy: 0.8491 | f-acore: 0.8476\n",
            "Test:  loss: 0.8908 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0111 | accuracy: 0.5000 | f1: 0.4999\n",
            "Epoch 00360\n",
            "Train: loss: 0.3448 | accuracy: 0.8391 | f-acore: 0.8381\n",
            "Test:  loss: 0.8794 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0129 | accuracy: 0.5030 | f1: 0.5029\n",
            "Epoch 00361\n",
            "Train: loss: 0.3547 | accuracy: 0.8448 | f-acore: 0.8446\n",
            "Test:  loss: 0.8722 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 0.9986 | accuracy: 0.4970 | f1: 0.4968\n",
            "Epoch 00362\n",
            "Train: loss: 0.3238 | accuracy: 0.8707 | f-acore: 0.8698\n",
            "Test:  loss: 0.8823 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0130 | accuracy: 0.4970 | f1: 0.4938\n",
            "Epoch 00363\n",
            "Train: loss: 0.3476 | accuracy: 0.8491 | f-acore: 0.8476\n",
            "Test:  loss: 0.8762 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0114 | accuracy: 0.4881 | f1: 0.4872\n",
            "Epoch 00364\n",
            "Train: loss: 0.3675 | accuracy: 0.8391 | f-acore: 0.8382\n",
            "Test:  loss: 0.9296 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0204 | accuracy: 0.4940 | f1: 0.4929\n",
            "Epoch 00365\n",
            "Train: loss: 0.3373 | accuracy: 0.8534 | f-acore: 0.8523\n",
            "Test:  loss: 0.8888 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0159 | accuracy: 0.4881 | f1: 0.4872\n",
            "Epoch 00366\n",
            "Train: loss: 0.3571 | accuracy: 0.8463 | f-acore: 0.8457\n",
            "Test:  loss: 0.8467 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0222 | accuracy: 0.4970 | f1: 0.4965\n",
            "Epoch 00367\n",
            "Train: loss: 0.3349 | accuracy: 0.8592 | f-acore: 0.8585\n",
            "Test:  loss: 0.9070 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0406 | accuracy: 0.4940 | f1: 0.4922\n",
            "Epoch 00368\n",
            "Train: loss: 0.3405 | accuracy: 0.8534 | f-acore: 0.8520\n",
            "Test:  loss: 0.8817 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0232 | accuracy: 0.4970 | f1: 0.4960\n",
            "Epoch 00369\n",
            "Train: loss: 0.3425 | accuracy: 0.8348 | f-acore: 0.8343\n",
            "Test:  loss: 0.8901 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0369 | accuracy: 0.4940 | f1: 0.4929\n",
            "Epoch 00370\n",
            "Train: loss: 0.3607 | accuracy: 0.8420 | f-acore: 0.8407\n",
            "Test:  loss: 0.8974 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0251 | accuracy: 0.4940 | f1: 0.4915\n",
            "Epoch 00371\n",
            "Train: loss: 0.3258 | accuracy: 0.8420 | f-acore: 0.8410\n",
            "Test:  loss: 0.9133 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0291 | accuracy: 0.5000 | f1: 0.4978\n",
            "Epoch 00372\n",
            "Train: loss: 0.3494 | accuracy: 0.8391 | f-acore: 0.8384\n",
            "Test:  loss: 0.9222 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 1.0320 | accuracy: 0.4970 | f1: 0.4954\n",
            "Epoch 00373\n",
            "Train: loss: 0.3422 | accuracy: 0.8448 | f-acore: 0.8435\n",
            "Test:  loss: 0.9281 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0060 | accuracy: 0.5060 | f1: 0.5048\n",
            "Epoch 00374\n",
            "Train: loss: 0.3321 | accuracy: 0.8520 | f-acore: 0.8513\n",
            "Test:  loss: 0.8909 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0226 | accuracy: 0.5089 | f1: 0.5084\n",
            "Epoch 00375\n",
            "Train: loss: 0.3222 | accuracy: 0.8678 | f-acore: 0.8675\n",
            "Test:  loss: 0.8855 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0564 | accuracy: 0.5060 | f1: 0.5053\n",
            "Epoch 00376\n",
            "Train: loss: 0.3366 | accuracy: 0.8606 | f-acore: 0.8597\n",
            "Test:  loss: 0.9228 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 1.0246 | accuracy: 0.4940 | f1: 0.4919\n",
            "Epoch 00377\n",
            "Train: loss: 0.3405 | accuracy: 0.8563 | f-acore: 0.8555\n",
            "Test:  loss: 0.9298 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 1.0173 | accuracy: 0.5030 | f1: 0.5017\n",
            "Epoch 00378\n",
            "Train: loss: 0.3666 | accuracy: 0.8477 | f-acore: 0.8471\n",
            "Test:  loss: 0.9135 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0409 | accuracy: 0.5000 | f1: 0.4998\n",
            "Epoch 00379\n",
            "Train: loss: 0.3388 | accuracy: 0.8707 | f-acore: 0.8701\n",
            "Test:  loss: 0.9245 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0553 | accuracy: 0.4970 | f1: 0.4963\n",
            "Epoch 00380\n",
            "Train: loss: 0.3457 | accuracy: 0.8506 | f-acore: 0.8499\n",
            "Test:  loss: 0.9735 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0444 | accuracy: 0.4851 | f1: 0.4831\n",
            "Epoch 00381\n",
            "Train: loss: 0.3330 | accuracy: 0.8434 | f-acore: 0.8421\n",
            "Test:  loss: 0.9154 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0264 | accuracy: 0.4940 | f1: 0.4936\n",
            "Epoch 00382\n",
            "Train: loss: 0.3220 | accuracy: 0.8635 | f-acore: 0.8629\n",
            "Test:  loss: 0.8927 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0444 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00383\n",
            "Train: loss: 0.3342 | accuracy: 0.8621 | f-acore: 0.8618\n",
            "Test:  loss: 0.9049 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0518 | accuracy: 0.5060 | f1: 0.5055\n",
            "Epoch 00384\n",
            "Train: loss: 0.3388 | accuracy: 0.8448 | f-acore: 0.8434\n",
            "Test:  loss: 0.9026 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0564 | accuracy: 0.5000 | f1: 0.4982\n",
            "Epoch 00385\n",
            "Train: loss: 0.3224 | accuracy: 0.8592 | f-acore: 0.8585\n",
            "Test:  loss: 0.8314 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0563 | accuracy: 0.5000 | f1: 0.4994\n",
            "Epoch 00386\n",
            "Train: loss: 0.3275 | accuracy: 0.8592 | f-acore: 0.8585\n",
            "Test:  loss: 0.8834 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0412 | accuracy: 0.4970 | f1: 0.4965\n",
            "Epoch 00387\n",
            "Train: loss: 0.3353 | accuracy: 0.8506 | f-acore: 0.8492\n",
            "Test:  loss: 0.9467 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0574 | accuracy: 0.5030 | f1: 0.5024\n",
            "Epoch 00388\n",
            "Train: loss: 0.3259 | accuracy: 0.8592 | f-acore: 0.8588\n",
            "Test:  loss: 0.9246 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0798 | accuracy: 0.5060 | f1: 0.5051\n",
            "Epoch 00389\n",
            "Train: loss: 0.3423 | accuracy: 0.8448 | f-acore: 0.8440\n",
            "Test:  loss: 0.8543 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0633 | accuracy: 0.5060 | f1: 0.5051\n",
            "Epoch 00390\n",
            "Train: loss: 0.3469 | accuracy: 0.8477 | f-acore: 0.8472\n",
            "Test:  loss: 0.8499 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0699 | accuracy: 0.4970 | f1: 0.4951\n",
            "Epoch 00391\n",
            "Train: loss: 0.3525 | accuracy: 0.8491 | f-acore: 0.8479\n",
            "Test:  loss: 0.9152 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 1.0486 | accuracy: 0.4911 | f1: 0.4882\n",
            "Epoch 00392\n",
            "Train: loss: 0.3197 | accuracy: 0.8635 | f-acore: 0.8625\n",
            "Test:  loss: 0.9242 | accuracy: 0.5833 | f1: 0.5556\n",
            "Validation:  loss: 1.0517 | accuracy: 0.5238 | f1: 0.5234\n",
            "Epoch 00393\n",
            "Train: loss: 0.3546 | accuracy: 0.8405 | f-acore: 0.8397\n",
            "Test:  loss: 0.8720 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0528 | accuracy: 0.5208 | f1: 0.5206\n",
            "Epoch 00394\n",
            "Train: loss: 0.3484 | accuracy: 0.8534 | f-acore: 0.8531\n",
            "Test:  loss: 0.9101 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0924 | accuracy: 0.5089 | f1: 0.5082\n",
            "Epoch 00395\n",
            "Train: loss: 0.3102 | accuracy: 0.8649 | f-acore: 0.8644\n",
            "Test:  loss: 0.9371 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.1054 | accuracy: 0.4940 | f1: 0.4915\n",
            "Epoch 00396\n",
            "Train: loss: 0.3350 | accuracy: 0.8578 | f-acore: 0.8564\n",
            "Test:  loss: 0.9105 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0339 | accuracy: 0.5089 | f1: 0.5077\n",
            "Epoch 00397\n",
            "Train: loss: 0.3301 | accuracy: 0.8707 | f-acore: 0.8697\n",
            "Test:  loss: 0.8793 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0820 | accuracy: 0.4970 | f1: 0.4963\n",
            "Epoch 00398\n",
            "Train: loss: 0.3391 | accuracy: 0.8578 | f-acore: 0.8571\n",
            "Test:  loss: 0.9076 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0601 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00399\n",
            "Train: loss: 0.3297 | accuracy: 0.8491 | f-acore: 0.8485\n",
            "Test:  loss: 0.8993 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0761 | accuracy: 0.4970 | f1: 0.4960\n",
            "Epoch 00400\n",
            "Train: loss: 0.3250 | accuracy: 0.8621 | f-acore: 0.8613\n",
            "Test:  loss: 0.9342 | accuracy: 0.6250 | f1: 0.6080\n",
            "Validation:  loss: 1.0695 | accuracy: 0.5119 | f1: 0.5108\n",
            "-----------------------------------------------------------------------------------------\n",
            "ETH-USD\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6914 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6939 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00002\n",
            "Train: loss: 0.6902 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6948 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6872 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00003\n",
            "Train: loss: 0.6898 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6956 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6868 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00004\n",
            "Train: loss: 0.6897 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6964 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6836 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00005\n",
            "Train: loss: 0.6877 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6963 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6824 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00006\n",
            "Train: loss: 0.6878 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6965 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6838 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00007\n",
            "Train: loss: 0.6887 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6964 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6824 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00008\n",
            "Train: loss: 0.6882 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6949 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00009\n",
            "Train: loss: 0.6861 | accuracy: 0.5388 | f-acore: 0.3501\n",
            "Test:  loss: 0.6939 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6889 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00010\n",
            "Train: loss: 0.6876 | accuracy: 0.5417 | f-acore: 0.3730\n",
            "Test:  loss: 0.6925 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00011\n",
            "Train: loss: 0.6872 | accuracy: 0.5402 | f-acore: 0.3893\n",
            "Test:  loss: 0.6930 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6884 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00012\n",
            "Train: loss: 0.6857 | accuracy: 0.5575 | f-acore: 0.4581\n",
            "Test:  loss: 0.6917 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6865 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00013\n",
            "Train: loss: 0.6857 | accuracy: 0.5589 | f-acore: 0.4988\n",
            "Test:  loss: 0.6915 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6864 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00014\n",
            "Train: loss: 0.6848 | accuracy: 0.5474 | f-acore: 0.5071\n",
            "Test:  loss: 0.6912 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6884 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00015\n",
            "Train: loss: 0.6846 | accuracy: 0.5733 | f-acore: 0.5353\n",
            "Test:  loss: 0.6927 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6902 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00016\n",
            "Train: loss: 0.6875 | accuracy: 0.5618 | f-acore: 0.4862\n",
            "Test:  loss: 0.6945 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6909 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00017\n",
            "Train: loss: 0.6871 | accuracy: 0.5546 | f-acore: 0.4274\n",
            "Test:  loss: 0.6952 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00018\n",
            "Train: loss: 0.6833 | accuracy: 0.5618 | f-acore: 0.4525\n",
            "Test:  loss: 0.6935 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6893 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00019\n",
            "Train: loss: 0.6839 | accuracy: 0.5503 | f-acore: 0.4855\n",
            "Test:  loss: 0.6929 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6904 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00020\n",
            "Train: loss: 0.6843 | accuracy: 0.5560 | f-acore: 0.4666\n",
            "Test:  loss: 0.6952 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00021\n",
            "Train: loss: 0.6845 | accuracy: 0.5603 | f-acore: 0.4725\n",
            "Test:  loss: 0.6953 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6860 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00022\n",
            "Train: loss: 0.6855 | accuracy: 0.5503 | f-acore: 0.4502\n",
            "Test:  loss: 0.6950 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6848 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00023\n",
            "Train: loss: 0.6834 | accuracy: 0.5632 | f-acore: 0.4760\n",
            "Test:  loss: 0.6946 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6924 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00024\n",
            "Train: loss: 0.6827 | accuracy: 0.5647 | f-acore: 0.5019\n",
            "Test:  loss: 0.6936 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00025\n",
            "Train: loss: 0.6830 | accuracy: 0.5661 | f-acore: 0.5075\n",
            "Test:  loss: 0.6937 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00026\n",
            "Train: loss: 0.6838 | accuracy: 0.5733 | f-acore: 0.5225\n",
            "Test:  loss: 0.6936 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6900 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00027\n",
            "Train: loss: 0.6816 | accuracy: 0.5675 | f-acore: 0.5129\n",
            "Test:  loss: 0.6934 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6904 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00028\n",
            "Train: loss: 0.6838 | accuracy: 0.5675 | f-acore: 0.5200\n",
            "Test:  loss: 0.6942 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6894 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00029\n",
            "Train: loss: 0.6833 | accuracy: 0.5848 | f-acore: 0.5436\n",
            "Test:  loss: 0.6941 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6871 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00030\n",
            "Train: loss: 0.6805 | accuracy: 0.5733 | f-acore: 0.5369\n",
            "Test:  loss: 0.6932 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00031\n",
            "Train: loss: 0.6811 | accuracy: 0.5603 | f-acore: 0.5358\n",
            "Test:  loss: 0.6907 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6922 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00032\n",
            "Train: loss: 0.6820 | accuracy: 0.5805 | f-acore: 0.5558\n",
            "Test:  loss: 0.6925 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6888 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00033\n",
            "Train: loss: 0.6829 | accuracy: 0.5790 | f-acore: 0.5513\n",
            "Test:  loss: 0.6915 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6876 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00034\n",
            "Train: loss: 0.6819 | accuracy: 0.5876 | f-acore: 0.5667\n",
            "Test:  loss: 0.6929 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00035\n",
            "Train: loss: 0.6786 | accuracy: 0.5761 | f-acore: 0.5503\n",
            "Test:  loss: 0.6950 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6862 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00036\n",
            "Train: loss: 0.6783 | accuracy: 0.5862 | f-acore: 0.5506\n",
            "Test:  loss: 0.6966 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6889 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00037\n",
            "Train: loss: 0.6757 | accuracy: 0.5876 | f-acore: 0.5556\n",
            "Test:  loss: 0.6950 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6843 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00038\n",
            "Train: loss: 0.6770 | accuracy: 0.5761 | f-acore: 0.5489\n",
            "Test:  loss: 0.6949 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6856 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00039\n",
            "Train: loss: 0.6771 | accuracy: 0.5690 | f-acore: 0.5373\n",
            "Test:  loss: 0.6961 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6959 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00040\n",
            "Train: loss: 0.6745 | accuracy: 0.6092 | f-acore: 0.5844\n",
            "Test:  loss: 0.6959 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6905 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00041\n",
            "Train: loss: 0.6724 | accuracy: 0.5819 | f-acore: 0.5550\n",
            "Test:  loss: 0.6986 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6889 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00042\n",
            "Train: loss: 0.6730 | accuracy: 0.6020 | f-acore: 0.5731\n",
            "Test:  loss: 0.7007 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6850 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00043\n",
            "Train: loss: 0.6684 | accuracy: 0.6006 | f-acore: 0.5726\n",
            "Test:  loss: 0.7024 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00044\n",
            "Train: loss: 0.6738 | accuracy: 0.5934 | f-acore: 0.5639\n",
            "Test:  loss: 0.7026 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6903 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00045\n",
            "Train: loss: 0.6698 | accuracy: 0.5776 | f-acore: 0.5258\n",
            "Test:  loss: 0.7077 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6923 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00046\n",
            "Train: loss: 0.6711 | accuracy: 0.5977 | f-acore: 0.5493\n",
            "Test:  loss: 0.7079 | accuracy: 0.4583 | f1: 0.3143\n",
            "Validation:  loss: 0.6865 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00047\n",
            "Train: loss: 0.6729 | accuracy: 0.5991 | f-acore: 0.5701\n",
            "Test:  loss: 0.7067 | accuracy: 0.5000 | f1: 0.4375\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00048\n",
            "Train: loss: 0.6716 | accuracy: 0.5876 | f-acore: 0.5700\n",
            "Test:  loss: 0.7042 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00049\n",
            "Train: loss: 0.6676 | accuracy: 0.6135 | f-acore: 0.5965\n",
            "Test:  loss: 0.7094 | accuracy: 0.4167 | f1: 0.2941\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00050\n",
            "Train: loss: 0.6681 | accuracy: 0.6078 | f-acore: 0.5806\n",
            "Test:  loss: 0.7080 | accuracy: 0.5417 | f1: 0.4991\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00051\n",
            "Train: loss: 0.6658 | accuracy: 0.6164 | f-acore: 0.5941\n",
            "Test:  loss: 0.7086 | accuracy: 0.5417 | f1: 0.4991\n",
            "Validation:  loss: 0.6938 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00052\n",
            "Train: loss: 0.6634 | accuracy: 0.6135 | f-acore: 0.5917\n",
            "Test:  loss: 0.7116 | accuracy: 0.5000 | f1: 0.4375\n",
            "Validation:  loss: 0.6983 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00053\n",
            "Train: loss: 0.6601 | accuracy: 0.6193 | f-acore: 0.5948\n",
            "Test:  loss: 0.7123 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6894 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00054\n",
            "Train: loss: 0.6584 | accuracy: 0.6193 | f-acore: 0.5960\n",
            "Test:  loss: 0.7158 | accuracy: 0.5000 | f1: 0.4375\n",
            "Validation:  loss: 0.6876 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00055\n",
            "Train: loss: 0.6649 | accuracy: 0.6006 | f-acore: 0.5777\n",
            "Test:  loss: 0.7108 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6934 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00056\n",
            "Train: loss: 0.6699 | accuracy: 0.5991 | f-acore: 0.5782\n",
            "Test:  loss: 0.7154 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00057\n",
            "Train: loss: 0.6653 | accuracy: 0.6193 | f-acore: 0.5954\n",
            "Test:  loss: 0.7147 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00058\n",
            "Train: loss: 0.6617 | accuracy: 0.6121 | f-acore: 0.5822\n",
            "Test:  loss: 0.7171 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6906 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00059\n",
            "Train: loss: 0.6555 | accuracy: 0.6178 | f-acore: 0.5953\n",
            "Test:  loss: 0.7164 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6877 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00060\n",
            "Train: loss: 0.6563 | accuracy: 0.6264 | f-acore: 0.6097\n",
            "Test:  loss: 0.7227 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00061\n",
            "Train: loss: 0.6595 | accuracy: 0.6078 | f-acore: 0.5862\n",
            "Test:  loss: 0.7283 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00062\n",
            "Train: loss: 0.6586 | accuracy: 0.6236 | f-acore: 0.6009\n",
            "Test:  loss: 0.7295 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00063\n",
            "Train: loss: 0.6578 | accuracy: 0.6149 | f-acore: 0.5886\n",
            "Test:  loss: 0.7276 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00064\n",
            "Train: loss: 0.6567 | accuracy: 0.6193 | f-acore: 0.5966\n",
            "Test:  loss: 0.7290 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6949 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00065\n",
            "Train: loss: 0.6582 | accuracy: 0.6164 | f-acore: 0.5958\n",
            "Test:  loss: 0.7275 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6952 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00066\n",
            "Train: loss: 0.6596 | accuracy: 0.6307 | f-acore: 0.6125\n",
            "Test:  loss: 0.7292 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.6857 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00067\n",
            "Train: loss: 0.6516 | accuracy: 0.6149 | f-acore: 0.5972\n",
            "Test:  loss: 0.7318 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.6914 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00068\n",
            "Train: loss: 0.6571 | accuracy: 0.6207 | f-acore: 0.6001\n",
            "Test:  loss: 0.7287 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00069\n",
            "Train: loss: 0.6544 | accuracy: 0.6193 | f-acore: 0.6057\n",
            "Test:  loss: 0.7277 | accuracy: 0.3750 | f1: 0.3739\n",
            "Validation:  loss: 0.6838 | accuracy: 0.5655 | f1: 0.3674\n",
            "Epoch 00070\n",
            "Train: loss: 0.6522 | accuracy: 0.6164 | f-acore: 0.6032\n",
            "Test:  loss: 0.7351 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00071\n",
            "Train: loss: 0.6480 | accuracy: 0.6221 | f-acore: 0.5966\n",
            "Test:  loss: 0.7433 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6897 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00072\n",
            "Train: loss: 0.6467 | accuracy: 0.6379 | f-acore: 0.6150\n",
            "Test:  loss: 0.7447 | accuracy: 0.5000 | f1: 0.4667\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00073\n",
            "Train: loss: 0.6422 | accuracy: 0.6408 | f-acore: 0.6208\n",
            "Test:  loss: 0.7385 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.6927 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00074\n",
            "Train: loss: 0.6441 | accuracy: 0.6236 | f-acore: 0.6047\n",
            "Test:  loss: 0.7451 | accuracy: 0.4167 | f1: 0.4126\n",
            "Validation:  loss: 0.6879 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00075\n",
            "Train: loss: 0.6355 | accuracy: 0.6451 | f-acore: 0.6299\n",
            "Test:  loss: 0.7500 | accuracy: 0.3750 | f1: 0.3739\n",
            "Validation:  loss: 0.6854 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00076\n",
            "Train: loss: 0.6450 | accuracy: 0.6264 | f-acore: 0.6134\n",
            "Test:  loss: 0.7598 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6811 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00077\n",
            "Train: loss: 0.6489 | accuracy: 0.6365 | f-acore: 0.6180\n",
            "Test:  loss: 0.7521 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6833 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00078\n",
            "Train: loss: 0.6405 | accuracy: 0.6336 | f-acore: 0.6218\n",
            "Test:  loss: 0.7546 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6836 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00079\n",
            "Train: loss: 0.6361 | accuracy: 0.6422 | f-acore: 0.6231\n",
            "Test:  loss: 0.7667 | accuracy: 0.4167 | f1: 0.3438\n",
            "Validation:  loss: 0.6865 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00080\n",
            "Train: loss: 0.6458 | accuracy: 0.6336 | f-acore: 0.5981\n",
            "Test:  loss: 0.7681 | accuracy: 0.3333 | f1: 0.2500\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00081\n",
            "Train: loss: 0.6435 | accuracy: 0.6351 | f-acore: 0.6136\n",
            "Test:  loss: 0.7598 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5685 | f1: 0.3807\n",
            "Epoch 00082\n",
            "Train: loss: 0.6381 | accuracy: 0.6351 | f-acore: 0.6289\n",
            "Test:  loss: 0.7554 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6811 | accuracy: 0.5685 | f1: 0.3865\n",
            "Epoch 00083\n",
            "Train: loss: 0.6296 | accuracy: 0.6595 | f-acore: 0.6496\n",
            "Test:  loss: 0.7652 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6941 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00084\n",
            "Train: loss: 0.6367 | accuracy: 0.6408 | f-acore: 0.6233\n",
            "Test:  loss: 0.7636 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.6873 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00085\n",
            "Train: loss: 0.6285 | accuracy: 0.6624 | f-acore: 0.6438\n",
            "Test:  loss: 0.7605 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6916 | accuracy: 0.5625 | f1: 0.3600\n",
            "Epoch 00086\n",
            "Train: loss: 0.6374 | accuracy: 0.6293 | f-acore: 0.6058\n",
            "Test:  loss: 0.7552 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6909 | accuracy: 0.5655 | f1: 0.3674\n",
            "Epoch 00087\n",
            "Train: loss: 0.6345 | accuracy: 0.6466 | f-acore: 0.6298\n",
            "Test:  loss: 0.7530 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6835 | accuracy: 0.5625 | f1: 0.3780\n",
            "Epoch 00088\n",
            "Train: loss: 0.6330 | accuracy: 0.6466 | f-acore: 0.6288\n",
            "Test:  loss: 0.7549 | accuracy: 0.3333 | f1: 0.2889\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5655 | f1: 0.3735\n",
            "Epoch 00089\n",
            "Train: loss: 0.6308 | accuracy: 0.6595 | f-acore: 0.6453\n",
            "Test:  loss: 0.7538 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6848 | accuracy: 0.5595 | f1: 0.3822\n",
            "Epoch 00090\n",
            "Train: loss: 0.6310 | accuracy: 0.6624 | f-acore: 0.6500\n",
            "Test:  loss: 0.7587 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6840 | accuracy: 0.5685 | f1: 0.3748\n",
            "Epoch 00091\n",
            "Train: loss: 0.6232 | accuracy: 0.6437 | f-acore: 0.6312\n",
            "Test:  loss: 0.7613 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6925 | accuracy: 0.5595 | f1: 0.3709\n",
            "Epoch 00092\n",
            "Train: loss: 0.6139 | accuracy: 0.6638 | f-acore: 0.6474\n",
            "Test:  loss: 0.7594 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5685 | f1: 0.3974\n",
            "Epoch 00093\n",
            "Train: loss: 0.6280 | accuracy: 0.6365 | f-acore: 0.6240\n",
            "Test:  loss: 0.7537 | accuracy: 0.3333 | f1: 0.2889\n",
            "Validation:  loss: 0.6844 | accuracy: 0.5714 | f1: 0.4240\n",
            "Epoch 00094\n",
            "Train: loss: 0.6238 | accuracy: 0.6580 | f-acore: 0.6432\n",
            "Test:  loss: 0.7574 | accuracy: 0.3333 | f1: 0.2500\n",
            "Validation:  loss: 0.6836 | accuracy: 0.5625 | f1: 0.3780\n",
            "Epoch 00095\n",
            "Train: loss: 0.6187 | accuracy: 0.6580 | f-acore: 0.6400\n",
            "Test:  loss: 0.7629 | accuracy: 0.3333 | f1: 0.2500\n",
            "Validation:  loss: 0.6887 | accuracy: 0.5595 | f1: 0.3588\n",
            "Epoch 00096\n",
            "Train: loss: 0.6218 | accuracy: 0.6552 | f-acore: 0.6419\n",
            "Test:  loss: 0.7526 | accuracy: 0.5000 | f1: 0.4965\n",
            "Validation:  loss: 0.6793 | accuracy: 0.5774 | f1: 0.4452\n",
            "Epoch 00097\n",
            "Train: loss: 0.6208 | accuracy: 0.6365 | f-acore: 0.6329\n",
            "Test:  loss: 0.7500 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.6857 | accuracy: 0.5744 | f1: 0.4516\n",
            "Epoch 00098\n",
            "Train: loss: 0.6104 | accuracy: 0.6681 | f-acore: 0.6591\n",
            "Test:  loss: 0.7570 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5625 | f1: 0.3945\n",
            "Epoch 00099\n",
            "Train: loss: 0.6048 | accuracy: 0.6767 | f-acore: 0.6637\n",
            "Test:  loss: 0.7594 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6879 | accuracy: 0.5685 | f1: 0.4027\n",
            "Epoch 00100\n",
            "Train: loss: 0.6165 | accuracy: 0.6652 | f-acore: 0.6558\n",
            "Test:  loss: 0.7624 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.6897 | accuracy: 0.5714 | f1: 0.4144\n",
            "Epoch 00101\n",
            "Train: loss: 0.6135 | accuracy: 0.6667 | f-acore: 0.6554\n",
            "Test:  loss: 0.7615 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6849 | accuracy: 0.5744 | f1: 0.4516\n",
            "Epoch 00102\n",
            "Train: loss: 0.6162 | accuracy: 0.6523 | f-acore: 0.6420\n",
            "Test:  loss: 0.7564 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6871 | accuracy: 0.5685 | f1: 0.4269\n",
            "Epoch 00103\n",
            "Train: loss: 0.6043 | accuracy: 0.6681 | f-acore: 0.6574\n",
            "Test:  loss: 0.7598 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6876 | accuracy: 0.5685 | f1: 0.4078\n",
            "Epoch 00104\n",
            "Train: loss: 0.5975 | accuracy: 0.6853 | f-acore: 0.6752\n",
            "Test:  loss: 0.7601 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6851 | accuracy: 0.5655 | f1: 0.4112\n",
            "Epoch 00105\n",
            "Train: loss: 0.6050 | accuracy: 0.6782 | f-acore: 0.6665\n",
            "Test:  loss: 0.7635 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5774 | f1: 0.4365\n",
            "Epoch 00106\n",
            "Train: loss: 0.6035 | accuracy: 0.6624 | f-acore: 0.6545\n",
            "Test:  loss: 0.7662 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6862 | accuracy: 0.5804 | f1: 0.4553\n",
            "Epoch 00107\n",
            "Train: loss: 0.6050 | accuracy: 0.6695 | f-acore: 0.6591\n",
            "Test:  loss: 0.7736 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6935 | accuracy: 0.5655 | f1: 0.3960\n",
            "Epoch 00108\n",
            "Train: loss: 0.6034 | accuracy: 0.6796 | f-acore: 0.6651\n",
            "Test:  loss: 0.7749 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6847 | accuracy: 0.5744 | f1: 0.4256\n",
            "Epoch 00109\n",
            "Train: loss: 0.6058 | accuracy: 0.6724 | f-acore: 0.6666\n",
            "Test:  loss: 0.7665 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6866 | accuracy: 0.5774 | f1: 0.4452\n",
            "Epoch 00110\n",
            "Train: loss: 0.5944 | accuracy: 0.6997 | f-acore: 0.6949\n",
            "Test:  loss: 0.7685 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6910 | accuracy: 0.5714 | f1: 0.4286\n",
            "Epoch 00111\n",
            "Train: loss: 0.5899 | accuracy: 0.6739 | f-acore: 0.6633\n",
            "Test:  loss: 0.7745 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5744 | f1: 0.4209\n",
            "Epoch 00112\n",
            "Train: loss: 0.6001 | accuracy: 0.6724 | f-acore: 0.6643\n",
            "Test:  loss: 0.7782 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6851 | accuracy: 0.5685 | f1: 0.4628\n",
            "Epoch 00113\n",
            "Train: loss: 0.5947 | accuracy: 0.6724 | f-acore: 0.6666\n",
            "Test:  loss: 0.7826 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5774 | f1: 0.4650\n",
            "Epoch 00114\n",
            "Train: loss: 0.5864 | accuracy: 0.6753 | f-acore: 0.6667\n",
            "Test:  loss: 0.7928 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6959 | accuracy: 0.5685 | f1: 0.4027\n",
            "Epoch 00115\n",
            "Train: loss: 0.5947 | accuracy: 0.6897 | f-acore: 0.6784\n",
            "Test:  loss: 0.7894 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6861 | accuracy: 0.5804 | f1: 0.4553\n",
            "Epoch 00116\n",
            "Train: loss: 0.5891 | accuracy: 0.6925 | f-acore: 0.6834\n",
            "Test:  loss: 0.7918 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5714 | f1: 0.4683\n",
            "Epoch 00117\n",
            "Train: loss: 0.5958 | accuracy: 0.6695 | f-acore: 0.6642\n",
            "Test:  loss: 0.7931 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5833 | f1: 0.4725\n",
            "Epoch 00118\n",
            "Train: loss: 0.5893 | accuracy: 0.6710 | f-acore: 0.6653\n",
            "Test:  loss: 0.7967 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6863 | accuracy: 0.5774 | f1: 0.4722\n",
            "Epoch 00119\n",
            "Train: loss: 0.5878 | accuracy: 0.6882 | f-acore: 0.6785\n",
            "Test:  loss: 0.8023 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5714 | f1: 0.4612\n",
            "Epoch 00120\n",
            "Train: loss: 0.5889 | accuracy: 0.7026 | f-acore: 0.6972\n",
            "Test:  loss: 0.7945 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6834 | accuracy: 0.5506 | f1: 0.4999\n",
            "Epoch 00121\n",
            "Train: loss: 0.5777 | accuracy: 0.6925 | f-acore: 0.6866\n",
            "Test:  loss: 0.8085 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6920 | accuracy: 0.5595 | f1: 0.4670\n",
            "Epoch 00122\n",
            "Train: loss: 0.5882 | accuracy: 0.7098 | f-acore: 0.7006\n",
            "Test:  loss: 0.8085 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6903 | accuracy: 0.5804 | f1: 0.4669\n",
            "Epoch 00123\n",
            "Train: loss: 0.5684 | accuracy: 0.6925 | f-acore: 0.6831\n",
            "Test:  loss: 0.8175 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6851 | accuracy: 0.5714 | f1: 0.4537\n",
            "Epoch 00124\n",
            "Train: loss: 0.5713 | accuracy: 0.7112 | f-acore: 0.7016\n",
            "Test:  loss: 0.8136 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6906 | accuracy: 0.5565 | f1: 0.4585\n",
            "Epoch 00125\n",
            "Train: loss: 0.5710 | accuracy: 0.6940 | f-acore: 0.6898\n",
            "Test:  loss: 0.8008 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5565 | f1: 0.4650\n",
            "Epoch 00126\n",
            "Train: loss: 0.5751 | accuracy: 0.7055 | f-acore: 0.6999\n",
            "Test:  loss: 0.7967 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5536 | f1: 0.4425\n",
            "Epoch 00127\n",
            "Train: loss: 0.5703 | accuracy: 0.7155 | f-acore: 0.7062\n",
            "Test:  loss: 0.8063 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6952 | accuracy: 0.5565 | f1: 0.4771\n",
            "Epoch 00128\n",
            "Train: loss: 0.5651 | accuracy: 0.7141 | f-acore: 0.7072\n",
            "Test:  loss: 0.8037 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5565 | f1: 0.4905\n",
            "Epoch 00129\n",
            "Train: loss: 0.5730 | accuracy: 0.7069 | f-acore: 0.6994\n",
            "Test:  loss: 0.8047 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6939 | accuracy: 0.5565 | f1: 0.4681\n",
            "Epoch 00130\n",
            "Train: loss: 0.5663 | accuracy: 0.7055 | f-acore: 0.6989\n",
            "Test:  loss: 0.8135 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6924 | accuracy: 0.5595 | f1: 0.4535\n",
            "Epoch 00131\n",
            "Train: loss: 0.5669 | accuracy: 0.7141 | f-acore: 0.7072\n",
            "Test:  loss: 0.8043 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6916 | accuracy: 0.5536 | f1: 0.4531\n",
            "Epoch 00132\n",
            "Train: loss: 0.5675 | accuracy: 0.7112 | f-acore: 0.7062\n",
            "Test:  loss: 0.7975 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6926 | accuracy: 0.5625 | f1: 0.4690\n",
            "Epoch 00133\n",
            "Train: loss: 0.5697 | accuracy: 0.7040 | f-acore: 0.6992\n",
            "Test:  loss: 0.7963 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6904 | accuracy: 0.5595 | f1: 0.4926\n",
            "Epoch 00134\n",
            "Train: loss: 0.5661 | accuracy: 0.7069 | f-acore: 0.7041\n",
            "Test:  loss: 0.7957 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6873 | accuracy: 0.5565 | f1: 0.4826\n",
            "Epoch 00135\n",
            "Train: loss: 0.5577 | accuracy: 0.7241 | f-acore: 0.7197\n",
            "Test:  loss: 0.8046 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6947 | accuracy: 0.5565 | f1: 0.4771\n",
            "Epoch 00136\n",
            "Train: loss: 0.5529 | accuracy: 0.7141 | f-acore: 0.7063\n",
            "Test:  loss: 0.8096 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6948 | accuracy: 0.5536 | f1: 0.4691\n",
            "Epoch 00137\n",
            "Train: loss: 0.5592 | accuracy: 0.7141 | f-acore: 0.7103\n",
            "Test:  loss: 0.8070 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6899 | accuracy: 0.5625 | f1: 0.5044\n",
            "Epoch 00138\n",
            "Train: loss: 0.5681 | accuracy: 0.7055 | f-acore: 0.6981\n",
            "Test:  loss: 0.8075 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6926 | accuracy: 0.5446 | f1: 0.4439\n",
            "Epoch 00139\n",
            "Train: loss: 0.5584 | accuracy: 0.7155 | f-acore: 0.7090\n",
            "Test:  loss: 0.8057 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6932 | accuracy: 0.5565 | f1: 0.4681\n",
            "Epoch 00140\n",
            "Train: loss: 0.5525 | accuracy: 0.7069 | f-acore: 0.7015\n",
            "Test:  loss: 0.7955 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6972 | accuracy: 0.5595 | f1: 0.4926\n",
            "Epoch 00141\n",
            "Train: loss: 0.5356 | accuracy: 0.7284 | f-acore: 0.7231\n",
            "Test:  loss: 0.7999 | accuracy: 0.4583 | f1: 0.4338\n",
            "Validation:  loss: 0.7013 | accuracy: 0.5565 | f1: 0.4954\n",
            "Epoch 00142\n",
            "Train: loss: 0.5492 | accuracy: 0.7155 | f-acore: 0.7115\n",
            "Test:  loss: 0.8077 | accuracy: 0.4167 | f1: 0.3778\n",
            "Validation:  loss: 0.6951 | accuracy: 0.5506 | f1: 0.4861\n",
            "Epoch 00143\n",
            "Train: loss: 0.5503 | accuracy: 0.7371 | f-acore: 0.7305\n",
            "Test:  loss: 0.8107 | accuracy: 0.3750 | f1: 0.3169\n",
            "Validation:  loss: 0.7033 | accuracy: 0.5595 | f1: 0.4570\n",
            "Epoch 00144\n",
            "Train: loss: 0.5455 | accuracy: 0.7184 | f-acore: 0.7129\n",
            "Test:  loss: 0.7955 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5506 | f1: 0.4886\n",
            "Epoch 00145\n",
            "Train: loss: 0.5380 | accuracy: 0.7414 | f-acore: 0.7368\n",
            "Test:  loss: 0.7994 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6989 | accuracy: 0.5506 | f1: 0.4836\n",
            "Epoch 00146\n",
            "Train: loss: 0.5462 | accuracy: 0.7256 | f-acore: 0.7227\n",
            "Test:  loss: 0.8029 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7091 | accuracy: 0.5387 | f1: 0.4844\n",
            "Epoch 00147\n",
            "Train: loss: 0.5578 | accuracy: 0.7198 | f-acore: 0.7140\n",
            "Test:  loss: 0.8097 | accuracy: 0.3333 | f1: 0.2889\n",
            "Validation:  loss: 0.7118 | accuracy: 0.5685 | f1: 0.4883\n",
            "Epoch 00148\n",
            "Train: loss: 0.5397 | accuracy: 0.7313 | f-acore: 0.7269\n",
            "Test:  loss: 0.7919 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6995 | accuracy: 0.5417 | f1: 0.5062\n",
            "Epoch 00149\n",
            "Train: loss: 0.5437 | accuracy: 0.7342 | f-acore: 0.7320\n",
            "Test:  loss: 0.8023 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.6945 | accuracy: 0.5774 | f1: 0.5030\n",
            "Epoch 00150\n",
            "Train: loss: 0.5320 | accuracy: 0.7371 | f-acore: 0.7316\n",
            "Test:  loss: 0.7999 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7073 | accuracy: 0.5714 | f1: 0.4782\n",
            "Epoch 00151\n",
            "Train: loss: 0.5468 | accuracy: 0.7256 | f-acore: 0.7208\n",
            "Test:  loss: 0.8054 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7131 | accuracy: 0.5387 | f1: 0.4888\n",
            "Epoch 00152\n",
            "Train: loss: 0.5348 | accuracy: 0.7256 | f-acore: 0.7218\n",
            "Test:  loss: 0.8132 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7058 | accuracy: 0.5476 | f1: 0.4955\n",
            "Epoch 00153\n",
            "Train: loss: 0.5383 | accuracy: 0.7299 | f-acore: 0.7263\n",
            "Test:  loss: 0.8102 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7001 | accuracy: 0.5536 | f1: 0.5000\n",
            "Epoch 00154\n",
            "Train: loss: 0.5164 | accuracy: 0.7543 | f-acore: 0.7490\n",
            "Test:  loss: 0.8113 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5685 | f1: 0.4854\n",
            "Epoch 00155\n",
            "Train: loss: 0.5367 | accuracy: 0.7342 | f-acore: 0.7317\n",
            "Test:  loss: 0.8191 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7176 | accuracy: 0.5655 | f1: 0.4917\n",
            "Epoch 00156\n",
            "Train: loss: 0.5382 | accuracy: 0.7457 | f-acore: 0.7415\n",
            "Test:  loss: 0.8202 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7033 | accuracy: 0.5536 | f1: 0.4778\n",
            "Epoch 00157\n",
            "Train: loss: 0.5306 | accuracy: 0.7443 | f-acore: 0.7403\n",
            "Test:  loss: 0.8196 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7015 | accuracy: 0.5446 | f1: 0.4842\n",
            "Epoch 00158\n",
            "Train: loss: 0.5301 | accuracy: 0.7543 | f-acore: 0.7477\n",
            "Test:  loss: 0.8203 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7000 | accuracy: 0.5565 | f1: 0.4954\n",
            "Epoch 00159\n",
            "Train: loss: 0.5500 | accuracy: 0.7126 | f-acore: 0.7105\n",
            "Test:  loss: 0.8006 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.6977 | accuracy: 0.5476 | f1: 0.5092\n",
            "Epoch 00160\n",
            "Train: loss: 0.5137 | accuracy: 0.7629 | f-acore: 0.7611\n",
            "Test:  loss: 0.8075 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7106 | accuracy: 0.5536 | f1: 0.4883\n",
            "Epoch 00161\n",
            "Train: loss: 0.5202 | accuracy: 0.7572 | f-acore: 0.7528\n",
            "Test:  loss: 0.8197 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7332 | accuracy: 0.5625 | f1: 0.4589\n",
            "Epoch 00162\n",
            "Train: loss: 0.5201 | accuracy: 0.7486 | f-acore: 0.7429\n",
            "Test:  loss: 0.8092 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7135 | accuracy: 0.5565 | f1: 0.5065\n",
            "Epoch 00163\n",
            "Train: loss: 0.5161 | accuracy: 0.7342 | f-acore: 0.7323\n",
            "Test:  loss: 0.8014 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7060 | accuracy: 0.5327 | f1: 0.4940\n",
            "Epoch 00164\n",
            "Train: loss: 0.5190 | accuracy: 0.7586 | f-acore: 0.7559\n",
            "Test:  loss: 0.8189 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7044 | accuracy: 0.5506 | f1: 0.4861\n",
            "Epoch 00165\n",
            "Train: loss: 0.5127 | accuracy: 0.7529 | f-acore: 0.7468\n",
            "Test:  loss: 0.8352 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7150 | accuracy: 0.5595 | f1: 0.4820\n",
            "Epoch 00166\n",
            "Train: loss: 0.5164 | accuracy: 0.7529 | f-acore: 0.7472\n",
            "Test:  loss: 0.8379 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7102 | accuracy: 0.5595 | f1: 0.4951\n",
            "Epoch 00167\n",
            "Train: loss: 0.5137 | accuracy: 0.7572 | f-acore: 0.7520\n",
            "Test:  loss: 0.8185 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7203 | accuracy: 0.5417 | f1: 0.5062\n",
            "Epoch 00168\n",
            "Train: loss: 0.5309 | accuracy: 0.7529 | f-acore: 0.7502\n",
            "Test:  loss: 0.8168 | accuracy: 0.5000 | f1: 0.4965\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5327 | f1: 0.5226\n",
            "Epoch 00169\n",
            "Train: loss: 0.5045 | accuracy: 0.7586 | f-acore: 0.7577\n",
            "Test:  loss: 0.8384 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5357 | f1: 0.5063\n",
            "Epoch 00170\n",
            "Train: loss: 0.5199 | accuracy: 0.7428 | f-acore: 0.7385\n",
            "Test:  loss: 0.8736 | accuracy: 0.3333 | f1: 0.2889\n",
            "Validation:  loss: 0.7176 | accuracy: 0.5565 | f1: 0.4826\n",
            "Epoch 00171\n",
            "Train: loss: 0.5107 | accuracy: 0.7543 | f-acore: 0.7481\n",
            "Test:  loss: 0.8713 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7148 | accuracy: 0.5476 | f1: 0.4789\n",
            "Epoch 00172\n",
            "Train: loss: 0.4910 | accuracy: 0.7859 | f-acore: 0.7819\n",
            "Test:  loss: 0.8566 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7065 | accuracy: 0.5476 | f1: 0.4976\n",
            "Epoch 00173\n",
            "Train: loss: 0.5191 | accuracy: 0.7615 | f-acore: 0.7576\n",
            "Test:  loss: 0.8543 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7284 | accuracy: 0.5565 | f1: 0.4853\n",
            "Epoch 00174\n",
            "Train: loss: 0.5121 | accuracy: 0.7471 | f-acore: 0.7420\n",
            "Test:  loss: 0.8402 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7131 | accuracy: 0.5625 | f1: 0.5067\n",
            "Epoch 00175\n",
            "Train: loss: 0.5165 | accuracy: 0.7486 | f-acore: 0.7444\n",
            "Test:  loss: 0.8401 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7153 | accuracy: 0.5446 | f1: 0.5032\n",
            "Epoch 00176\n",
            "Train: loss: 0.5078 | accuracy: 0.7486 | f-acore: 0.7464\n",
            "Test:  loss: 0.8264 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7124 | accuracy: 0.5357 | f1: 0.5078\n",
            "Epoch 00177\n",
            "Train: loss: 0.5167 | accuracy: 0.7615 | f-acore: 0.7599\n",
            "Test:  loss: 0.8418 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5417 | f1: 0.5095\n",
            "Epoch 00178\n",
            "Train: loss: 0.5191 | accuracy: 0.7658 | f-acore: 0.7608\n",
            "Test:  loss: 0.8579 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7222 | accuracy: 0.5417 | f1: 0.4772\n",
            "Epoch 00179\n",
            "Train: loss: 0.4953 | accuracy: 0.7701 | f-acore: 0.7664\n",
            "Test:  loss: 0.8283 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7172 | accuracy: 0.5655 | f1: 0.5112\n",
            "Epoch 00180\n",
            "Train: loss: 0.5160 | accuracy: 0.7586 | f-acore: 0.7556\n",
            "Test:  loss: 0.8476 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7193 | accuracy: 0.5565 | f1: 0.5086\n",
            "Epoch 00181\n",
            "Train: loss: 0.5158 | accuracy: 0.7371 | f-acore: 0.7333\n",
            "Test:  loss: 0.8652 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7191 | accuracy: 0.5417 | f1: 0.5062\n",
            "Epoch 00182\n",
            "Train: loss: 0.4834 | accuracy: 0.7917 | f-acore: 0.7895\n",
            "Test:  loss: 0.8641 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7190 | accuracy: 0.5417 | f1: 0.5196\n",
            "Epoch 00183\n",
            "Train: loss: 0.4979 | accuracy: 0.7658 | f-acore: 0.7636\n",
            "Test:  loss: 0.8844 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7125 | accuracy: 0.5595 | f1: 0.5286\n",
            "Epoch 00184\n",
            "Train: loss: 0.5075 | accuracy: 0.7629 | f-acore: 0.7597\n",
            "Test:  loss: 0.8804 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7207 | accuracy: 0.5625 | f1: 0.5279\n",
            "Epoch 00185\n",
            "Train: loss: 0.4777 | accuracy: 0.7730 | f-acore: 0.7707\n",
            "Test:  loss: 0.8719 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7151 | accuracy: 0.5476 | f1: 0.5143\n",
            "Epoch 00186\n",
            "Train: loss: 0.4928 | accuracy: 0.7701 | f-acore: 0.7673\n",
            "Test:  loss: 0.8778 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7333 | accuracy: 0.5506 | f1: 0.5020\n",
            "Epoch 00187\n",
            "Train: loss: 0.4817 | accuracy: 0.7644 | f-acore: 0.7612\n",
            "Test:  loss: 0.8755 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7389 | accuracy: 0.5387 | f1: 0.4725\n",
            "Epoch 00188\n",
            "Train: loss: 0.4918 | accuracy: 0.7658 | f-acore: 0.7617\n",
            "Test:  loss: 0.8899 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7391 | accuracy: 0.5446 | f1: 0.4715\n",
            "Epoch 00189\n",
            "Train: loss: 0.4862 | accuracy: 0.7773 | f-acore: 0.7747\n",
            "Test:  loss: 0.9061 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7260 | accuracy: 0.5536 | f1: 0.5174\n",
            "Epoch 00190\n",
            "Train: loss: 0.5004 | accuracy: 0.7629 | f-acore: 0.7601\n",
            "Test:  loss: 0.8979 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7278 | accuracy: 0.5357 | f1: 0.5093\n",
            "Epoch 00191\n",
            "Train: loss: 0.4740 | accuracy: 0.7802 | f-acore: 0.7779\n",
            "Test:  loss: 0.9203 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7230 | accuracy: 0.5327 | f1: 0.4921\n",
            "Epoch 00192\n",
            "Train: loss: 0.4844 | accuracy: 0.7802 | f-acore: 0.7770\n",
            "Test:  loss: 0.9269 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7271 | accuracy: 0.5387 | f1: 0.4844\n",
            "Epoch 00193\n",
            "Train: loss: 0.4798 | accuracy: 0.7888 | f-acore: 0.7857\n",
            "Test:  loss: 0.9133 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7312 | accuracy: 0.5298 | f1: 0.4841\n",
            "Epoch 00194\n",
            "Train: loss: 0.4806 | accuracy: 0.7802 | f-acore: 0.7781\n",
            "Test:  loss: 0.9068 | accuracy: 0.3750 | f1: 0.3466\n",
            "Validation:  loss: 0.7340 | accuracy: 0.5357 | f1: 0.4865\n",
            "Epoch 00195\n",
            "Train: loss: 0.5058 | accuracy: 0.7543 | f-acore: 0.7498\n",
            "Test:  loss: 0.9210 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7350 | accuracy: 0.5446 | f1: 0.4768\n",
            "Epoch 00196\n",
            "Train: loss: 0.4830 | accuracy: 0.7816 | f-acore: 0.7794\n",
            "Test:  loss: 0.9094 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7180 | accuracy: 0.5476 | f1: 0.5017\n",
            "Epoch 00197\n",
            "Train: loss: 0.4811 | accuracy: 0.7816 | f-acore: 0.7791\n",
            "Test:  loss: 0.9020 | accuracy: 0.4583 | f1: 0.4497\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5536 | f1: 0.5102\n",
            "Epoch 00198\n",
            "Train: loss: 0.4636 | accuracy: 0.7816 | f-acore: 0.7785\n",
            "Test:  loss: 0.9223 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7388 | accuracy: 0.5476 | f1: 0.4955\n",
            "Epoch 00199\n",
            "Train: loss: 0.4657 | accuracy: 0.7816 | f-acore: 0.7762\n",
            "Test:  loss: 0.9241 | accuracy: 0.4167 | f1: 0.4000\n",
            "Validation:  loss: 0.7529 | accuracy: 0.5387 | f1: 0.4929\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m model_path \u001b[38;5;241m=\u001b[39m next_file(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m index, join(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Results/\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(config_path)))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# for b, a, in train_dataloader[index]:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#   print(\"opppppppppppppppppppppppppppppppppppppppppppppppppppppppp\")\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[35], line 101\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_data, val_dataset, test_dataset)\u001b[0m\n\u001b[1;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# print(\"Batch_logit\")\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# print(batch_logit)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#Convert to CPU for processing\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m batch_label \u001b[38;5;241m=\u001b[39m batch_label\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    105\u001b[0m pred \u001b[38;5;241m=\u001b[39m (batch_logit \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Main.py script\n",
        "#Training loop\n",
        "import models #TODO: Put this at top of imports\n",
        "\n",
        "#Set up GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU instead.\")\n",
        "\n",
        "gen_num = 1 #TODO: Define this in the Config file\n",
        "for iteration in range(gen_num):\n",
        "\n",
        "\n",
        "  for index, _ in y_train.items():\n",
        "    #Get Model output path\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    print(index)\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    model_path = next_file(config['model']['type'] + index, join(\"./Results/\", os.path.basename(config_path)))\n",
        "    # for b, a, in train_dataloader[index]:\n",
        "    #   print(\"opppppppppppppppppppppppppppppppppppppppppppppppppppppppp\")\n",
        "    train(config, train_data[index], val_data[index], test_data[index])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
